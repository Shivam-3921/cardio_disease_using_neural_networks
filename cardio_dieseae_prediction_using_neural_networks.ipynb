{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433834</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443711</td>\n",
       "      <td>-0.845741</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.309613</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>0.759448</td>\n",
       "      <td>0.771644</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.245845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>-0.706160</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.745799</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.550076</td>\n",
       "      <td>1.335923</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.806166</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>-1.264486</td>\n",
       "      <td>-1.485474</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.992694</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.628408</td>\n",
       "      <td>-0.496787</td>\n",
       "      <td>-0.356915</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.073318</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897072</td>\n",
       "      <td>1.317775</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.662604</td>\n",
       "      <td>1.457357</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.727567</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.775183</td>\n",
       "      <td>-0.217624</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>-0.426996</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    height    weight     ap_hi     ap_lo  cholesterol  \\\n",
       "0 -0.433834       2  0.443711 -0.845741 -0.921194 -0.134931            1   \n",
       "1  0.309613       1 -1.018961  0.759448  0.771644  0.877460            3   \n",
       "2 -0.245845       1  0.078043 -0.706160  0.207365 -1.147322            3   \n",
       "3 -0.745799       2  0.565600  0.550076  1.335923  1.889851            1   \n",
       "4 -0.806166       1 -1.018961 -1.264486 -1.485474 -2.159713            1   \n",
       "5  0.992694       1 -1.628408 -0.496787 -0.356915 -0.134931            2   \n",
       "6  1.073318       1 -0.897072  1.317775  0.207365 -0.134931            3   \n",
       "7  1.264143       2  1.662604  1.457357  0.207365  0.877460            3   \n",
       "8 -0.727567       1 -0.775183 -0.217624 -0.921194 -1.147322            1   \n",
       "9  0.149985       1 -0.043847 -0.426996 -0.921194 -2.159713            1   \n",
       "\n",
       "   gluc  smoke  active  cardio  \n",
       "0     1      0       1       0  \n",
       "1     1      0       1       1  \n",
       "2     1      0       0       1  \n",
       "3     1      0       1       1  \n",
       "4     1      0       0       0  \n",
       "5     2      0       0       0  \n",
       "6     1      0       1       0  \n",
       "7     3      0       1       1  \n",
       "8     1      0       1       0  \n",
       "9     1      0       0       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the preprocessed data\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into trainning and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"cardio\"],axis=1)\n",
    "y = df[\"cardio\"].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQNRJREFUeJzt3Qe8VdWdL/A/RYoFsNEiItHEBkIERSyMhQHrSHQcWxQbRiMmiE+UPMWWhBdsWIiMGtsbHdFM0FiCEhA1gqIosTNq8EmigIkCSpR632etmXPmXqqEu7n3wvf7+eycu/ded599+AQXv7PW/q96FRUVFQEAAABUu/rVf0kAAAAgEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURuoFqcdppp8UOO+xQ07cBAAC1itANG7h69ep9rW3ixIlR23zwwQdx+umnx4477hhNmjSJ1q1bR8+ePePyyy//u673xBNPxBVXXFHt9wkAdbn//tvf/pb7x7W5lj4avr56FRUVFWvRHqhj/u3f/q3K/r333hvjxo2L//t//2+V4//4j/8YrVq1+rvfZ/HixbFs2bJo3LhxVIf33nsv9tprr2jatGmcccYZeRT9448/jldeeSV++9vfxldffbXW1xwwYECMHDky/GcPgNpuffXfyV/+8pfYdtttc2D+OsFXHw1rp+FatgfqmO9973tV9l944YXcaS9/fGXfem+66aZf+3022WSTqE433HBDfPHFFzFt2rRo3759lXNz5syp1vcCgA2l/14f9NGwdkwvB+LAAw+Mjh07xtSpU/PUsBS2f/zjH+dzjzzySBxxxBHRtm3bPIqdppFdffXVsXTp0tU+052mnaVpb9dee23cdttt+ffS76dvxl966aU13tP7778f22233QqdedKyZcsVjqVv1g844IDYbLPNYosttsj3/Oabb1a5v/QNelJ5Wh4A1FVphtmIESNi9913z1O804j397///fjss8+qtHv55ZejT58+sc022+TR6Q4dOuQR6lJ/nUa5kyuvvLLcP65uxFsfDWvHSDeQ/fWvf43DDjssTjjhhPwtemmq2t133x2bb755DBo0KL9OmDAhhg4dGvPnz49rrrlmjde9//774/PPP8//CEgd6PDhw+OYY46JP/7xj6sdHU8d+e9+97v8fgcffPBq3yNNtevXr1/+B8XPf/7zPEp/6623xv777x+vvvpq/jIgvf9HH3200ql5AFAXpb4t9dPp2eof/vCHMWPGjLjlllty3/f888/nfjaNPPfu3TsH60suuSRatGiRg/avf/3rfI10PPWZ5557bnz3u9/NfXSyxx57rPJ99dGwltIz3cDG47zzzksPS1U59g//8A/52KhRo1Zo/7e//W2FY9///vcrNt1004qvvvqqfKxfv34V7du3L+/PmDEjX3Prrbeu+PTTT8vHH3nkkXz80UcfXe19vvHGGxVNmzbNbbt06VLxox/9qOLhhx+uWLBgQZV2n3/+eUWLFi0q+vfvX+X4rFmzKpo3b17l+Mo+OwDUBcv3Yc8991zev++++6q0Gzt2bJXjY8aMyfsvvfTSKq/9ySef5DaXX37517oXfTSsHdPLgSxN/U7flC8vTUMrSSPWqdhKmiKWvql+55131njd448/PrbccsvyfvrdJI10r06aKpeeFUuj7ukb+RtvvDH69u2bR+Bvv/32crv0rfjcuXPjxBNPzPdW2ho0aBDdu3ePp59++mv/GQBAXfHQQw9F8+bNcyG1yv1f165d88y0Uv+XRraTxx57LBc9rQ76aFg7ppcD2Te+8Y1o1KjRCsfTM1eXXnppnkKWppRXNm/evDVed/vtt6+yXwrgyz9vtjLf/va38zSz9Pz4W2+9lf/BkKann3322fl5tF69esW7776b265qeluzZs3W+D4AUNek/i/1wyt7hrpyQbN/+Id/iGOPPTY/r50KoKU6Likgn3TSSeu04og+Gr4+oRtYYUS7JH07nTrr1CleddVV5bU405IgF198cS7gsibp2+yVWZslQdI1OnXqlLcePXrEQQcdFPfdd1/u0Ev3kDr+tEbo8ho29J85ADY8qf9LgTv1hytTKo6W6qn86le/ytXPH3300XjyySdzEbXrrrsuH0uj4utCHw1r5v/pwCpNnDgxF1hLxVZSVfOSVKilpnTr1i2/pvVAk/RFQJL+4ZE6+NVRCRWADUXq/1Ixs/3222+lX5wvb5999snbT3/601zk9OSTT44HHnggzjrrrGrrH/XRsHKe6QbWOEpdeVR60aJF8Ytf/KLw937uuedW+uzZE088kV933nnn/JqqoaaR+J/97Gcrbf/JJ5+Uf05LlZRG8AGgLvuXf/mXPLU7LeO5vCVLlpT7uvQ41/Kzy7p06ZJfFy5cmF/TUqFr0z/qo2HtGOkGVmnffffNz2CnpT7SUiTpW+g0RWxtpob/vdKyImnd8LR0SWnZkjSt/d57742tttoqBg4cmI+lzjwtPXLKKafEnnvumZc8S1PqPvzww3j88cfzCEBaPiVJxWWS9FnSPwTSlwqpPQDUNenxr7TU1rBhw3JRs7QsWFoiLD1HnYqspeJm//zP/xz33HNP/rI8LQeWRp5TUdRU7Cz1n4cffni+Vhop32233WL06NH5We3Uz3bs2DFvK6OPhrW0ltXOgQ10ybDdd999pe2ff/75in322ScvDdK2bduKwYMHVzz55JP5Gk8//fQalwy75pprVrjm11mWJL1vuteOHTvmZUU22WSTiu23377itNNOq3j//fdXaJ/upU+fPrltkyZNKnbcccfc9uWXXy63WbJkScX5559fse2221bUq1fP0iQA1BmrWlLrtttuq+jatWvup7fYYouKTp065b76o48+yudfeeWVihNPPDH3oY0bN65o2bJlxZFHHlmlf0wmTZqUr9OoUaM19tP6aFg79dL/rG1QBwAAANbMM90AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIA2LuvDGZtmyZfHRRx/FFltsEfXq1avp2wGgDkureX7++efRtm3bqF/f9+PVTZ8NwPrsr4XuapI673bt2tX0bQCwAZk5c2Zst912NX0bGxx9NgDrs78WuqtJ+ra89AferFmzmr4dAOqw+fPn51BY6luoXvpsANZnfy10V5PS9LTUeevAAagOpj4XQ58NwPrsrz0oBgAAAAURugEAAKAgQjcAAAAUROgGAACADTF0Dxs2LPbaa69c7a1ly5bRt2/fmD59epU2Bx54YH4wvfJ2zjnnVGnz4YcfxhFHHBGbbrppvs5FF10US5YsqdJm4sSJseeee0bjxo1jp512irvvvnuF+xk5cmTssMMO0aRJk+jevXtMmTKloE8OAADAxqBGQ/czzzwT5513Xrzwwgsxbty4WLx4cfTu3TsWLFhQpV3//v3j448/Lm/Dhw8vn1u6dGkO3IsWLYpJkybFPffckwP10KFDy21mzJiR2xx00EExbdq0GDhwYJx11lnx5JNPltuMHj06Bg0aFJdffnm88sor0blz5+jTp0/MmTNnPf1pAAAAsKGpV1FRURG1xCeffJJHqlMY79mzZ3mku0uXLjFixIiV/s5vf/vbOPLII+Ojjz6KVq1a5WOjRo2Kiy++OF+vUaNG+efHH3883njjjfLvnXDCCTF37twYO3Zs3k8j22nU/ZZbbsn7y5Yty2uunX/++XHJJZd8rTXamjdvHvPmzbP8CADrRJ9SLH++AKzP/qRWPdOdbjbZaqutqhy/7777YptttomOHTvGkCFD4m9/+1v53OTJk6NTp07lwJ2kEer0B/Dmm2+W2/Tq1avKNVObdDxJo+RTp06t0qZ+/fp5v9RmeQsXLszvUXkDAACAyhpGLZFGltO07/322y+H65KTTjop2rdvH23bto3XXnstj1qn575//etf5/OzZs2qEriT0n46t7o2KSh/+eWX8dlnn+Vp6itr884776zyefQrr7yymj49AAAAG6JaE7rTs91p+vfvf//7KsfPPvvs8s9pRLtNmzZxyCGHxPvvvx877rhj1JQ04p6eAS9JAT5NRwcAAIBaFboHDBgQjz32WDz77LOx3XbbrbZtevY6ee+993Lobt269QpVxmfPnp1f07nSa+lY5TZp3n3Tpk2jQYMGeVtZm9I1lpeqoKcNAAAAauUz3amGWwrcY8aMiQkTJkSHDh3W+Dup+niSRryTHj16xOuvv16lyniqhJ4C9W677VZuM378+CrXSW3S8SQVW+vatWuVNmm6e9ovtQEAAIA6NdKdppTff//98cgjj+S1ukvPYKcKcGkEOk0hT+cPP/zw2HrrrfMz3RdccEGubL7HHnvktmmJsRSuTznllLyUWLrGpZdemq9dGolO63qnquSDBw+OM844Iwf8Bx98MFc0L0lTxfv16xfdunWLvffeO1dLT0uXnX766TX0pwMAAEBdV6Oh+9Zbby0vC1bZXXfdFaeddloegf7d735XDsDpmeljjz02h+qSNC08TU0/99xz86j0ZpttlsPzVVddVW6TRtBTwE6B/cYbb8xT2O+4445cwbzk+OOPz0uMpfW9U3BPy5Sl5cSWL64GAAAAdXKd7rrMmp8AVBd9SrH8+QKw0a7TDQAAABsSoRsAAAA25CXDWLmuF91b07cAMfWaU2v6FgBqPX02tYE+G2onI90AAABQECPdAABA4cwIYWOdEWKkGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYA1ujZZ5+No446Ktq2bRv16tWLhx9+uMr5ioqKGDp0aLRp0yaaNm0avXr1infffbdKm08//TROPvnkaNasWbRo0SLOPPPM+OKLL6q0ee211+KAAw6IJk2aRLt27WL48OEr3MtDDz0Uu+yyS27TqVOneOKJJwr61ACw7qzTDdR51v1kY1zzc31bsGBBdO7cOc4444w45phjVjifwvFNN90U99xzT3To0CEuu+yy6NOnT7z11ls5HCcpcH/88ccxbty4WLx4cZx++ulx9tlnx/3335/Pz58/P3r37p0D+6hRo+L111/P75cCemqXTJo0KU488cQYNmxYHHnkkfl3+/btG6+88kp07NhxPf+pAMCaCd0AwBoddthheVuZNMo9YsSIuPTSS+Poo4/Ox+69995o1apVHhE/4YQT4u23346xY8fGSy+9FN26dcttbr755jj88MPj2muvzSPo9913XyxatCjuvPPOaNSoUey+++4xbdq0uP7668uh+8Ybb4xDDz00Lrroorx/9dVX5xB/yy235KAOALWN6eUAwDqZMWNGzJo1K49QlzRv3jy6d+8ekydPzvvpNY1YlwJ3ktrXr18/XnzxxXKbnj175sBdkkbLp0+fHp999lm5TeX3KbUpvQ8A1DZGugGAdZICd5JGtitL+6Vz6bVly5ZVzjds2DC22mqrKm3S1PTlr1E6t+WWW+bX1b3PyixcuDBvJWkaOwCsL0a6AYANWnr+O428l7ZUoA0A1hehGwBYJ61bt86vs2fPrnI87ZfOpdc5c+ZUOb9kyZJc0bxym5Vdo/J7rKpN6fzKDBkyJObNm1feZs6cuQ6fFgDWjtANAKyTNCU8hd7x48dXmcKdntXu0aNH3k+vc+fOjalTp5bbTJgwIZYtW5af/S61SUuTpcrmJalI2s4775ynlpfaVH6fUpvS+6xM48aN8zJllTcAWF+EbgBgjdJ62qmSeNpKxdPSzx9++GFet3vgwIHxk5/8JH7zm9/kpb5OPfXUXJE8LeeV7LrrrrnqeP/+/WPKlCnx/PPPx4ABA3Jl89QuOemkk3IRtbR+95tvvhmjR4/O1coHDRpUvo8f/ehHuQr6ddddF++8805cccUV8fLLL+drAUBtpJAaALBGKdgedNBB5f1SEO7Xr1/cfffdMXjw4LyWd1raK41o77///jkcl9boTtKSYCkcH3LIIblq+bHHHpvX9i5Jz1s/9dRTcd5550XXrl1jm222iaFDh5aXC0v23XffvDZ3Wp7sxz/+cXzrW9/Ky5JZoxuA2kroBgDW6MADD8zrca9KGu2+6qqr8rYqqVJ5Csyrs8cee8Rzzz232jbHHXdc3gCgLjC9HAAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAABsiKF72LBhsddee8UWW2wRLVu2jL59+8b06dOrtPnqq6/ivPPOi6233jo233zzOPbYY2P27NlV2nz44YdxxBFHxKabbpqvc9FFF8WSJUuqtJk4cWLsueee0bhx49hpp53i7rvvXuF+Ro4cGTvssEM0adIkunfvHlOmTCnokwMAALAxqNHQ/cwzz+RA/cILL8S4ceNi8eLF0bt371iwYEG5zQUXXBCPPvpoPPTQQ7n9Rx99FMccc0z5/NKlS3PgXrRoUUyaNCnuueeeHKiHDh1abjNjxozc5qCDDopp06bFwIED46yzzoonn3yy3Gb06NExaNCguPzyy+OVV16Jzp07R58+fWLOnDnr8U8EAACADUnDmnzzsWPHVtlPYTmNVE+dOjV69uwZ8+bNi1/+8pdx//33x8EHH5zb3HXXXbHrrrvmoL7PPvvEU089FW+99Vb87ne/i1atWkWXLl3i6quvjosvvjiuuOKKaNSoUYwaNSo6dOgQ1113Xb5G+v3f//73ccMNN+RgnVx//fXRv3//OP300/N++p3HH3887rzzzrjkkkvW+58NAAAAdV+teqY7hexkq622yq8pfKfR7169epXb7LLLLrH99tvH5MmT83567dSpUw7cJSlIz58/P958881ym8rXKLUpXSONkqf3qtymfv36eb/UZnkLFy7M71F5AwAAgFoZupctW5anfe+3337RsWPHfGzWrFl5pLpFixZV2qaAnc6V2lQO3KXzpXOra5OC8pdffhl/+ctf8jT1lbUpXWNlz6M3b968vLVr126d/wwAAADYsNSa0J2e7X7jjTfigQceiLpgyJAheWS+tM2cObOmbwkAAIBapkaf6S4ZMGBAPPbYY/Hss8/GdtttVz7eunXrPPV77ty5VUa7U/XydK7UZvkq46Xq5pXbLF/xPO03a9YsmjZtGg0aNMjbytqUrrG8VAU9bQAAAFArR7orKipy4B4zZkxMmDAhFzurrGvXrrHJJpvE+PHjy8fSkmJpibAePXrk/fT6+uuvV6kyniqhp0C92267ldtUvkapTekaaQp7eq/KbdJ097RfagMAAAB1aqQ7TSlPlckfeeSRvFZ36fnp9Ix0GoFOr2eeeWZeyisVV0tB+vzzz89BOFUuT9ISYylcn3LKKTF8+PB8jUsvvTRfuzQSfc4558Qtt9wSgwcPjjPOOCMH/AcffDBXJy9J79GvX7/o1q1b7L333jFixIi8dFmpmjkAAADUqdB966235tcDDzywyvG0LNhpp52Wf07LeqVK4scee2yuGJ6qjv/iF78ot03TwtPU9HPPPTeH8c022yyH56uuuqrcJo2gp4Cd1vy+8cYb8xT2O+64o7xcWHL88cfHJ598ktf3TsE9LT2WljRbvrgaAAAA1InQnaaXr0mTJk1i5MiReVuV9u3bxxNPPLHa66Rg/+qrr662TZrqnjYAAADYoKqXAwAAwIZG6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0ArLOlS5fGZZddFh06dIimTZvGjjvuGFdffXWV5UHTz0OHDo02bdrkNr169Yp33323ynU+/fTTOPnkk6NZs2bRokWLOPPMM+OLL76o0ua1116LAw44IC8r2q5duxg+fPh6+5wAsLaEbgBgnf385z+PW2+9NW655ZZ4++23834KwzfffHO5Tdq/6aabYtSoUfHiiy/GZpttFn369Imvvvqq3CYF7jfffDPGjRsXjz32WDz77LNx9tlnl8/Pnz8/evfuHe3bt4+pU6fGNddcE1dccUXcdttt6/0zA8DX0fBrtQIAWI1JkybF0UcfHUcccUTe32GHHeLf//3fY8qUKeVR7hEjRsSll16a2yX33ntvtGrVKh5++OE44YQTclgfO3ZsvPTSS9GtW7fcJoX2ww8/PK699tpo27Zt3HfffbFo0aK48847o1GjRrH77rvHtGnT4vrrr68SzgGgtjDSDQCss3333TfGjx8f//mf/5n3//CHP8Tvf//7OOyww/L+jBkzYtasWXlKeUnz5s2je/fuMXny5LyfXtOU8lLgTlL7+vXr55HxUpuePXvmwF2SRsunT58en3322Xr7vADwdRnpBgDW2SWXXJKnfu+yyy7RoEGD/Iz3T3/60zxdPEmBO0kj25Wl/dK59NqyZcsq5xs2bBhbbbVVlTbpufHlr1E6t+WWW65wbwsXLsxbSbpPAFhfjHQDAOvswQcfzFO/77///njllVfinnvuyVPC02tNGzZsWB5VL22p+BoArC9CNwCwzi666KI82p2eze7UqVOccsopccEFF+TAm7Ru3Tq/zp49u8rvpf3SufQ6Z86cKueXLFmSK5pXbrOya1R+j+UNGTIk5s2bV95mzpxZbZ8bANZE6AYA1tnf/va3/Ox1ZWma+bJly/LPaUp4CsXpue/K07zTs9o9evTI++l17ty5uSp5yYQJE/I10rPfpTapovnixYvLbVKl85133nmlU8uTxo0b5yXIKm8AsL4I3QDAOjvqqKPyM9yPP/54fPDBBzFmzJhcUfy73/1uPl+vXr0YOHBg/OQnP4nf/OY38frrr8epp56aK5L37ds3t9l1113j0EMPjf79++eq588//3wMGDAgj56ndslJJ52Ui6il9bvT0mKjR4+OG2+8MQYNGlSjnx8AVkUhNQBgnaWlvS677LL4wQ9+kKeIp5D8/e9/P4YOHVpuM3jw4FiwYEFe2iuNaO+///55ibAmTZqU26TnwlPQPuSQQ/LI+bHHHpvX9i5Jz2Q/9dRTcd5550XXrl1jm222ye9huTAAaiuhGwBYZ1tssUVehzttq5JGu6+66qq8rUqqVJ6Ksa3OHnvsEc8999w63S8ArC+mlwMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAADYEEP3s88+G0cddVS0bds26tWrFw8//HCV86eddlo+Xnk79NBDq7T59NNP4+STT45mzZpFixYt4swzz4wvvviiSpvXXnstDjjggGjSpEm0a9cuhg8fvsK9PPTQQ7HLLrvkNp06dYonnniioE8NAADAxqJGQ/eCBQuic+fOMXLkyFW2SSH7448/Lm///u//XuV8CtxvvvlmjBs3Lh577LEc5M8+++zy+fnz50fv3r2jffv2MXXq1LjmmmviiiuuiNtuu63cZtKkSXHiiSfmwP7qq69G37598/bGG28U9MkBAADYGDSsyTc/7LDD8rY6jRs3jtatW6/03Ntvvx1jx46Nl156Kbp165aP3XzzzXH44YfHtddem0fQ77vvvli0aFHceeed0ahRo9h9991j2rRpcf3115fD+Y033pjD/UUXXZT3r7766hzib7nllhg1alS1f24AAAA2DrX+me6JEydGy5YtY+edd45zzz03/vrXv5bPTZ48OU8pLwXupFevXlG/fv148cUXy2169uyZA3dJnz59Yvr06fHZZ5+V26Tfqyy1SccBAACgTo50r0kafT7mmGOiQ4cO8f7778ePf/zjPDKewnCDBg1i1qxZOZBX1rBhw9hqq63yuSS9pt+vrFWrVuVzW265ZX4tHavcpnSNlVm4cGHeKk9jBwAAgDoTuk844YTyz6m42R577BE77rhjHv0+5JBDavTehg0bFldeeWWN3gMAAAC1W62fXl7ZN7/5zdhmm23ivffey/vpWe85c+ZUabNkyZJc0bz0HHh6nT17dpU2pf01tVnVs+TJkCFDYt68eeVt5syZ1fQpAQAA2FDUqdD9pz/9KT/T3aZNm7zfo0ePmDt3bq5KXjJhwoRYtmxZdO/evdwmVTRfvHhxuU0qkpaeEU9Ty0ttxo8fX+W9Upt0fHUF3tIyZZU3AAAAqDWhO62nnSqJpy2ZMWNG/vnDDz/M51I18RdeeCE++OCDHIqPPvro2GmnnXKRs2TXXXfNz333798/pkyZEs8//3wMGDAgT0tPlcuTk046KRdRS8uBpaXFRo8enauVDxo0qHwfP/rRj3IV9Ouuuy7eeeedvKTYyy+/nK8FAAAAdTJ0p2D7ne98J29JCsLp56FDh+ZCaa+99lr80z/9U3z729/Ooblr167x3HPP5VHmkrQk2C677JKf8U5Lhe2///5V1uBu3rx5PPXUUznQp9+/8MIL8/Urr+W97777xv33359/L60b/qtf/Soefvjh6Nix43r+EwEAAGBDUqOF1A488MCoqKhY5fknn3xyjddIlcpTYF6dVIAthfXVOe644/IGAAAAG+Uz3QAAAFCXCN0AAABQEKEbAAAACiJ0AwDV4s9//nN873vfi6233jqaNm0anTp1ykVTS1Idl1TMNC39mc736tUr3n333SrX+PTTT+Pkk0/OS3G2aNEiF1JNK5pUlgqtHnDAAdGkSZNo165dDB8+fL19RgBYW0I3ALDOPvvss9hvv/1ik002id/+9rfx1ltv5aU4t9xyy3KbFI5vuummGDVqVLz44oux2Wab5WVAv/rqq3KbFLjTEp/jxo2Lxx57LJ599tkqK47Mnz8/evfuHe3bt4+pU6fGNddck5f6rLxyCQDUJjVavRwA2DD8/Oc/z6POd911V/lYhw4dqoxyjxgxIi699NI4+uij87F77703WrVqlZfpPOGEE+Ltt9+OsWPHxksvvRTdunXLbW6++ea8JOi1114bbdu2zUuFLlq0KO68885o1KhR7L777jFt2rS4/vrrq4RzAKgtjHQDAOvsN7/5TQ7KafnNli1bxne+8524/fbby+dnzJgRs2bNylPKS5o3bx7du3ePyZMn5/30mqaUlwJ3ktrXr18/j4yX2vTs2TMH7pI0Wj59+vQ82r4yCxcuzCPklTcAWF+EbgBgnf3xj3+MW2+9Nb71rW/Fk08+Geeee2788Ic/jHvuuSefT4E7SSPblaX90rn0mgJ7ZQ0bNoytttqqSpuVXaPyeyxv2LBhOeCXtjQiDwDri9ANAKyzZcuWxZ577hk/+9nP8ih3murdv3///Px2TRsyZEjMmzevvM2cObOmbwmAjYjQDQCss1SRfLfddqtybNddd40PP/ww/9y6dev8Onv27Cpt0n7pXHqdM2dOlfNLlizJFc0rt1nZNSq/x/IaN26cq6FX3gCgVofugw8+OObOnbvC8fSMVDoHANS89dlfp8rl6bnqyv7zP/8zVxkvFVVLoXj8+PFV7iM9q92jR4+8n17T/aaq5CUTJkzIo+jp2e9Sm1TRfPHixeU2qdL5zjvvXKVSOgDU6dA9ceLEXDl0eWnJj+eee6467gsAWEfrs7++4IIL4oUXXsjTy9977724//778zJe5513Xj5fr169GDhwYPzkJz/JRddef/31OPXUU3NF8r59+5ZHxg899NA8LX3KlCnx/PPPx4ABA3Jl89QuOemkk3IRtbR+d1pabPTo0XHjjTfGoEGDqvXzAECNLBn22muvlX9O629WLliydOnSvMzHN77xjWq7OQBg7dVEf73XXnvFmDFj8vPTV111VR7ZTkuEpXW3SwYPHhwLFizIz3unEe39998/30uTJk3KbdKSYCloH3LIIblq+bHHHpvX9i5JhdCeeuqpHOa7du0a22yzTQwdOtRyYQBsGKG7S5cu+ZvqtK1sWlrTpk3zepoAQM2pqf76yCOPzNuqpPtJgTxtq5IqladR8tXZY489zKwDYMMM3WmNzYqKivjmN7+Zp31tu+225XNpqlda5qNBgwZF3CcA8DXprwGgjobuUjGUVNAEAKid9NcAUEdDd2XvvvtuPP3003lpj+U79fRsFQBQ8/TXAFAHQ/ftt98e5557bi5ekpb/SM9olaSfdeIAUPP01wBQR0N3Wu7jpz/9aVx88cXVf0cAQLXQXwNAHV2n+7PPPovjjjuu+u8GAKg2+msAqKOhO3XgaY1MAKD20l8DQB2dXr7TTjvFZZddFi+88EJ06tQpNtlkkyrnf/jDH1bX/QEAfyf9NQDU0dB92223xeabbx7PPPNM3ipLhVl04gBQ8/TXAFBHQ/eMGTOq/04AgGqlvwaAOvpMNwAAAFDQSPcZZ5yx2vN33nnn33NZAKAa6a8BoI6G7rQESWWLFy+ON954I+bOnRsHH3xwdd0bALAO9NcAUEdD95gxY1Y4tmzZsjj33HNjxx13rI77AgDWkf4aADagZ7rr168fgwYNihtuuKG6LgkAVDP9NQDU4UJq77//fixZsqQ6LwkAVDP9NQDU8unl6RvyyioqKuLjjz+Oxx9/PPr161dd9wYArAP9NQDU0dD96quvrjBVbdttt43rrrtujZVSAYD1Q38NAHU0dD/99NPVfycAQLXSXwNAHQ3dJZ988klMnz49/7zzzjvnb88BgNpFfw0AdayQ2oIFC/K0tDZt2kTPnj3z1rZt2zjzzDPjb3/7W/XfJQCw1vTXAFBHQ3cqzPLMM8/Eo48+GnPnzs3bI488ko9deOGF1X+XAMBa018DQB2dXv4f//Ef8atf/SoOPPDA8rHDDz88mjZtGv/yL/8St956a3XeIwDwd9BfA0AdHelOU9JatWq1wvGWLVuargYAtYT+GgDqaOju0aNHXH755fHVV1+Vj3355Zdx5ZVX5nMAQM3TXwNAHZ1ePmLEiDj00ENju+22i86dO+djf/jDH6Jx48bx1FNPVfc9AgB/B/01ANTR0N2pU6d4991347777ot33nknHzvxxBPj5JNPzs+JAQA1T38NAHU0dA8bNiw/I9a/f/8qx++88868FujFF19cXfcHAPyd9NcAUEef6f7Xf/3X2GWXXVY4vvvuu8eoUaOq474AgHWkvwaAOhq6Z82aFW3atFnh+Lbbbhsff/xxddwXALCO9NcAUEdDd7t27eL5559f4Xg61rZt2+q4LwBgHemvAaCOPtOdng0bOHBgLF68OA4++OB8bPz48TF48OC48MILq/seAYC/g/4aAOpo6L7ooovir3/9a/zgBz+IRYsW5WNNmjTJBVmGDBlS3fcIAPwd9NcAUEdDd7169eLnP/95XHbZZfH222/nZUe+9a1v5XU/AYDaQX8NAHU0dJdsvvnmsddee1Xf3QAA1U5/DQB1rJAaAAAAsGZCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACADTF0P/vss3HUUUdF27Zto169evHwww9XOV9RURFDhw6NNm3aRNOmTaNXr17x7rvvVmnz6aefxsknnxzNmjWLFi1axJlnnhlffPFFlTavvfZaHHDAAdGkSZNo165dDB8+fIV7eeihh2KXXXbJbTp16hRPPPFEQZ8aAACAjUWNhu4FCxZE586dY+TIkSs9n8LxTTfdFKNGjYoXX3wxNttss+jTp0989dVX5TYpcL/55psxbty4eOyxx3KQP/vss8vn58+fH71794727dvH1KlT45prrokrrrgibrvttnKbSZMmxYknnpgD+6uvvhp9+/bN2xtvvFHwnwAAAAAbsoY1+eaHHXZY3lYmjXKPGDEiLr300jj66KPzsXvvvTdatWqVR8RPOOGEePvtt2Ps2LHx0ksvRbdu3XKbm2++OQ4//PC49tpr8wj6fffdF4sWLYo777wzGjVqFLvvvntMmzYtrr/++nI4v/HGG+PQQw+Niy66KO9fffXVOcTfcsstOfADAADABvVM94wZM2LWrFl5SnlJ8+bNo3v37jF58uS8n17TlPJS4E5S+/r16+eR8VKbnj175sBdkkbLp0+fHp999lm5TeX3KbUpvc/KLFy4MI+iV94AAACgToTuFLiTNLJdWdovnUuvLVu2rHK+YcOGsdVWW1Vps7JrVH6PVbUpnV+ZYcOG5S8BSlt6VhwAAADqROiu7YYMGRLz5s0rbzNnzqzpWwIAAKCWqbWhu3Xr1vl19uzZVY6n/dK59Dpnzpwq55csWZIrmldus7JrVH6PVbUpnV+Zxo0b54rplTcAAACoE6G7Q4cOOfSOHz++fCw9N52e1e7Ro0feT69z587NVclLJkyYEMuWLcvPfpfapIrmixcvLrdJRdJ23nnn2HLLLcttKr9PqU3pfQAAAKDOhe60nnaqJJ62UvG09POHH36Y1+0eOHBg/OQnP4nf/OY38frrr8epp56aK5Kn5bySXXfdNVcd79+/f0yZMiWef/75GDBgQK5sntolJ510Ui6ilpYDS0uLjR49OlcrHzRoUPk+fvSjH+Uq6Nddd1288847eUmxl19+OV8LAAAA6mToTsH2O9/5Tt6SFITTz0OHDs37gwcPjvPPPz8v7bXXXnvlkJ7CcZMmTcrXSEuC7bLLLnHIIYfkpcL233//KmtwpyJnTz31VA70Xbt2jQsvvDBfv/Ja3vvuu2/cf//9+ffSuuG/+tWv8rJkHTt2XK9/HgCwofg//+f/lL9AL/nqq6/ivPPOi6233jo233zzOPbYY1d4vCt98X7EEUfEpptumoulpuU806NjlU2cODH23HPP/KjXTjvtFHffffd6+1wAUKfW6T7wwAPzetyrkjrrq666Km+rkiqVp8C8OnvssUc899xzq21z3HHH5Q0AWDcvvfRS/Ou//mvufyu74IIL4vHHH4+HHnoofymeZpQdc8wxeaZasnTp0hy40+NlkyZNio8//jjPcttkk03iZz/7WW6TvkRPbc4555z8xXt6POyss86KNm3a5OU+AaC2qbXPdAMAdU+alXbyySfH7bffXq6dkqSVPn75y1/G9ddfHwcffHCefXbXXXflcP3CCy/kNmlm2ltvvRX/9m//Fl26dInDDjssrr766hg5cmQsWrQotxk1alSu+5IeCUuPmaXg/s///M9xww031NhnBoDVEboBgGqTpo+nkehevXpVOZ6KnqaippWPp8fDtt9++5g8eXLeT6+dOnWKVq1alduk0etUSDXVZSm1Wf7aqU3pGiuzcOHCfI3KGwBsFNPLAYANxwMPPBCvvPJKnl6+vFmzZuXCpi1atKhyPAXsdK7UpnLgLp0vnVtdmxSkv/zyy2jatOkK7z1s2LC48sorq+ETAsDaM9INAKyzmTNn5tVA0nPWlQue1gZDhgzJ09tLW7pXAFhfhG4AYJ2l6eNz5szJVcUbNmyYt2eeeSZuuumm/HMajU7PZc+dO7fK76Xq5alwWpJel69mXtpfU5tmzZqtdJQ7SVXO0/nKGwCsL0I3ALDO0tKdr7/+ekybNq28devWLRdVK/2cqpCnauMl06dPz0uE9ejRI++n13SNFN5Lxo0bl0PybrvtVm5T+RqlNqVrAEBt45luAGCdbbHFFtGxY8cqxzbbbLO8Jnfp+JlnnhmDBg3Ky32mIH3++efnsLzPPvvk8717987h+pRTTonhw4fn57cvvfTSXJwtjVYnaamwW265JQYPHhxnnHFGTJgwIR588MG8FBkA1EZCNwCwXqRlverXrx/HHntsriieqo7/4he/KJ9v0KBBPPbYY3HuuefmMJ5Ce79+/eKqq64qt0nLhaWAndb8vvHGG2O77baLO+64wxrdANRaQjcAUIiJEydW2U8F1tKa22lblfbt28cTTzyx2useeOCB8eqrr1bbfQJAkTzTDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAAGyMofuKK66IevXqVdl22WWX8vmvvvoqzjvvvNh6661j8803j2OPPTZmz55d5RoffvhhHHHEEbHppptGy5Yt46KLLoolS5ZUaTNx4sTYc889o3HjxrHTTjvF3Xffvd4+IwAAABuuWh26k9133z0+/vjj8vb73/++fO6CCy6IRx99NB566KF45pln4qOPPopjjjmmfH7p0qU5cC9atCgmTZoU99xzTw7UQ4cOLbeZMWNGbnPQQQfFtGnTYuDAgXHWWWfFk08+ud4/KwAAABuWhjV9A2vSsGHDaN269QrH582bF7/85S/j/vvvj4MPPjgfu+uuu2LXXXeNF154IfbZZ5946qmn4q233orf/e530apVq+jSpUtcffXVcfHFF+dR9EaNGsWoUaOiQ4cOcd111+VrpN9Pwf6GG26IPn36rPfPCwAAwIaj1o90v/vuu9G2bdv45je/GSeffHKeLp5MnTo1Fi9eHL169Sq3TVPPt99++5g8eXLeT6+dOnXKgbskBen58+fHm2++WW5T+RqlNqVrrMrChQvzdSpvAAAAUGdCd/fu3fN08LFjx8att96ap4IfcMAB8fnnn8esWbPySHWLFi2q/E4K2Olckl4rB+7S+dK51bVJIfrLL79c5b0NGzYsmjdvXt7atWtXbZ8bAOqa1C/utddescUWW+QaKn379o3p06dXaaMWCwAbo1odug877LA47rjjYo899sijz0888UTMnTs3HnzwwZq+tRgyZEie4l7aZs6cWdO3BAA1JtVWSYE6PeI1bty4PButd+/esWDBgnIbtVgA2BjV+me6K0uj2t/+9rfjvffei3/8x3/MnXIK4ZVHu9M35qVnwNPrlClTqlyj9I165TbLf8ue9ps1axZNmzZd5b2kb9fTBgBEnpVWWQrLaaQ6PQ7Ws2dPtVgA2GjV6pHu5X3xxRfx/vvvR5s2baJr166xySabxPjx48vn0zS2NC2tR48eeT+9vv766zFnzpxym/TtewrUu+22W7lN5WuU2pSuAQCsvRSyk6222qrGa7GowwJATarVoft//a//laefffDBB3ma2Xe/+91o0KBBnHjiifk56jPPPDMGDRoUTz/9dO7MTz/99ByW07flSZrWlsL1KaecEn/4wx/y1LNLL700T38rjVKfc8458cc//jEGDx4c77zzTvziF7/I09fTFDgAYO0tW7YsT/veb7/9omPHjvlYTdZiUYcFgJpUq6eX/+lPf8oB+69//Wtsu+22sf/+++cpaOnnJE0lq1+/fi7Ekr7FTt90p9BckgL6Y489Fueee24O45tttln069cvrrrqqnKbNEXt8ccfzyH7xhtvjO222y7uuOMOU9QA4O+Uvtx+44038rTv2iDVYUlf0pekgC54A7C+1OrQ/cADD6z2fJMmTWLkyJF5W5X27dvnAmyrc+CBB8arr776d98nAPBfBgwYkL/wfvbZZ/MX2SWphkpN1WJRhwWAmlSrp5cDAHVDRUVFDtxjxoyJCRMm5JlklanFAsDGqlaPdAMAdWdKeapM/sgjj+S1ukvPYKdnqNMIdOVaLKm4WgrS559//iprsQwfPjxfY2W1WG655ZZci+WMM87IAT/VYkmPigFAbWSkGwBYZ7feemuuWJ4e2UqrjJS20aNHl9ukWixHHnlkrsWSlhFLU8V//etfr1CLJb2mMP69730vTj311JXWYkmj2507d85Lh6nFAkBtZqQbAKiW6eVrohYLABsjI90AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROhezsiRI2OHHXaIJk2aRPfu3WPKlCk1fUsAwHL01wDUFUJ3JaNHj45BgwbF5ZdfHq+88kp07tw5+vTpE3PmzKnpWwMA/pv+GoC6ROiu5Prrr4/+/fvH6aefHrvttluMGjUqNt1007jzzjtr+tYAgP+mvwagLhG6/9uiRYti6tSp0atXr/Kx+vXr5/3JkyfX6L0BAP9Ffw1AXdOwpm+gtvjLX/4SS5cujVatWlU5nvbfeeedFdovXLgwbyXz5s3Lr/Pnz6+2e1q68Mtquxb8varz/9NF8XeFDe3vSel6FRUV1XrdjbG/TvTZbCxqe5/t7wkb2t+Tr9tfC91/p2HDhsWVV165wvF27drVyP1AUZrffE5N3wJstH9PPv/882jevHkh196Y6LPZWOizoWb+nqypvxa6/9s222wTDRo0iNmzZ1c5nvZbt269QvshQ4bkIi4ly5Yti08//TS23nrrqFev3nq5Z9b8zVP6B9XMmTOjWbNmNX07UCv5e1I7pW/MUwfetm3bmr6VOt9fJ/rs2s9/i2DN/D2pu/210P3fGjVqFF27do3x48dH3759y51y2h8wYMAK7Rs3bpy3ylq0aLHe7pevL/1HyX+YYPX8Pal9jHBXT3+d6LPrDv8tgjXz96Tu9ddCdyXpW/B+/fpFt27dYu+9944RI0bEggULcnVUAKB20F8DUJcI3ZUcf/zx8cknn8TQoUNj1qxZ0aVLlxg7duwKxVoAgJqjvwagLhG6l5Ompq1qehp1S5pKePnll68wpRD4H/6eUFfprzcs/lsEa+bvSd1Vr8J6JAAAAFCI+sVcFgAAABC6AQAAoCBCNwAAABRE6GaDNXLkyNhhhx2iSZMm0b1795gyZUpN3xLUKs8++2wcddRR0bZt26hXr148/PDDNX1LwEZIfw2rp7+u+4RuNkijR4/O67imCo+vvPJKdO7cOfr06RNz5syp6VuDWiOta5z+bqR/8ALUBP01rJn+uu5TvZwNUvqmfK+99opbbrkl7y9btizatWsX559/flxyySU1fXtQ66RvzseMGRN9+/at6VsBNiL6a1g7+uu6yUg3G5xFixbF1KlTo1evXuVj9evXz/uTJ0+u0XsDAP6L/hrYWAjdbHD+8pe/xNKlS6NVq1ZVjqf9WbNm1dh9AQD/Q38NbCyEbgAAACiI0M0GZ5tttokGDRrE7NmzqxxP+61bt66x+wIA/of+GthYCN1scBo1ahRdu3aN8ePHl4+lwixpv0ePHjV6bwDAf9FfAxuLhjV9A1CEtPxIv379olu3brH33nvHiBEj8nILp59+ek3fGtQaX3zxRbz33nvl/RkzZsS0adNiq622iu23375G7w3YOOivYc3013WfJcPYYKXlR6655ppcjKVLly5x00035aVJgP8yceLEOOigg1Y4nv4BfPfdd9fIPQEbH/01rJ7+uu4TugEAAKAgnukGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AZqjXr16sXDDz+cf/7ggw/y/rRp02r6tgCASvTXsHYarmV7gPWiXbt28fHHH8c222xT07cCAKyC/hrWzEg3sF4tWrToa7Vr0KBBtG7dOho29N0gAKxv+muoPkI3sEbLli2L4cOHx0477RSNGzeO7bffPn7605/mcxdffHF8+9vfjk033TS++c1vxmWXXRaLFy8u/+4VV1wRXbp0iTvuuCM6dOgQTZo0ycfffffd6NmzZ97fbbfdYty4cVXec2XT1Z555pnYe++98z20adMmLrnkkliyZMl6+3MAgNpMfw21k6+kgDUaMmRI3H777XHDDTfE/vvvn6eRvfPOO/ncFltsEXfffXe0bds2Xn/99ejfv38+Nnjw4PLvv/fee/Ef//Ef8etf/zp/I57+UXDMMcdEq1at4sUXX4x58+bFwIEDV3sPf/7zn+Pwww+P0047Le699978/um90j8C0j8UAGBjp7+GWqoCYDXmz59f0bhx44rbb7/9a7W/5pprKrp27Vrev/zyyys22WSTijlz5pSPPfnkkxUNGzas+POf/1w+9tvf/rYi/SdpzJgxeX/GjBl5/9VXX837P/7xjyt23nnnimXLlpV/Z+TIkRWbb755xdKlS6vlswJAXaW/htrLSDewWm+//XYsXLgwDjnkkJWeHz16dNx0003x/vvvxxdffJGnjzVr1qxKm/bt28e2225b5Zqp8Er6tr2kR48ea7yP1CZNYSvZb7/98nv+6U9/ylPoAGBjpb+G2ssz3cBqNW3adJXnJk+eHCeffHKeRvbYY4/Fq6++Gv/7f//vFYqvbLbZZuvhTgFg46W/htpL6AZW61vf+lbuyMePH7/CuUmTJuVvxVPH3a1bt9z2//2//7fGa+66664xc+bM/KxZyQsvvLDG30n/aKioSLPY/svzzz+fn0fbbrvt1vpzAcCGRH8NtZfp5cBqpcInqeJpKrTSqFGjPEXsk08+iTfffDN32h9++GE88MADsddee8Xjjz8eY8aMWeM1e/XqlSuo9uvXL6655pqYP39+/ofA6vzgBz+IESNGxPnnnx8DBgyI6dOnx+WXXx6DBg2K+vV9fwjAxk1/DbWX/+cDa5SWFbnwwgtj6NCh+Rvs448/PubMmRP/9E//FBdccEHuVNMyI+mb9NR2TVKnmzr7L7/8Mi8pctZZZ5WXNFmVb3zjG/HEE0/ElClTonPnznHOOefEmWeeGZdeemk1flIAqLv011A71UvV1Gr6JgAAAGBDZKQbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAFGM/w96fgR2KzgnVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the counts for training and test dataset\n",
    "fig, ax = plt.subplots(1,2,figsize = (10,5))\n",
    "sns.countplot(data=df, x = y_train, ax = ax[0])\n",
    "ax[0].set_title(\"Train Set\")\n",
    "sns.countplot(data=df, x = y_test, ax = ax[1])\n",
    "ax[1].set_title(\"Test Set\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is performed below on several parameters of the neural network such as number of units in any layer, activation functions, dropout rate, optimizer choice and learning rate. For simplicity, we will tune the number of hidden layers separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building neural network with one hidden layer and performing hyperparameter tuning\n",
    "def single_layer_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input Layer with fixed unit choices\n",
    "    model.add(Dense(hp.Choice('units', [256, 512, 1024, 2048])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3]) \n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband\n",
    "tuner = kt.Hyperband(\n",
    "    single_layer_model,\n",
    "    objective=['val_recall','val_precision'],  \n",
    "    max_epochs=20,           \n",
    "    factor=4,\n",
    "    directory='One hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 Complete [00h 00m 32s]\n",
      "multi_objective: -1.4554035067558289\n",
      "\n",
      "Best multi_objective So Far: -1.5089197158813477\n",
      "Total elapsed time: 00h 11m 41s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',         # Stop training if recall doesn't improve\n",
    "#     patience=4,                   # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True     # Restore best model\n",
    "# )\n",
    "\n",
    "# Performing hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    epochs=20,  \n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=64,\n",
    "    #callbacks=[early_stopping],  # Use Early Stopping\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 2048\n",
      "- Layer 1 Activation: leaky_relu\n",
      "- Layer 1 Dropout: 0.3\n",
      "- Optimizer: rmsprop\n",
      "- Learning Rate: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units')}\n",
    "- Layer 1 Activation: {best_hps.get('activation')}\n",
    "- Layer 1 Dropout: {best_hps.get('dropout')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6.5319 - precision_3: 0.5972 - recall_3: 0.6042 - val_loss: 4.4502 - val_precision_3: 0.5478 - val_recall_3: 0.9292\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5139 - precision_3: 0.6033 - recall_3: 0.6064 - val_loss: 4.2301 - val_precision_3: 0.6263 - val_recall_3: 0.5253\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.7894 - precision_3: 0.5992 - recall_3: 0.6004 - val_loss: 3.4305 - val_precision_3: 0.6064 - val_recall_3: 0.5225\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5172 - precision_3: 0.6071 - recall_3: 0.6051 - val_loss: 6.5250 - val_precision_3: 0.8346 - val_recall_3: 0.3881\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6301 - precision_3: 0.6034 - recall_3: 0.5980 - val_loss: 3.6663 - val_precision_3: 0.8057 - val_recall_3: 0.5096\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6171 - precision_3: 0.6052 - recall_3: 0.6034 - val_loss: 5.1126 - val_precision_3: 0.5261 - val_recall_3: 0.9710\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.7465 - precision_3: 0.6088 - recall_3: 0.6096 - val_loss: 4.7528 - val_precision_3: 0.7350 - val_recall_3: 0.3638\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.4834 - precision_3: 0.6076 - recall_3: 0.6061 - val_loss: 4.0962 - val_precision_3: 0.6943 - val_recall_3: 0.7612\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5119 - precision_3: 0.6040 - recall_3: 0.6048 - val_loss: 4.8169 - val_precision_3: 0.5652 - val_recall_3: 0.9217\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5565 - precision_3: 0.6116 - recall_3: 0.6109 - val_loss: 2.4778 - val_precision_3: 0.8121 - val_recall_3: 0.4943\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5849 - precision_3: 0.6067 - recall_3: 0.6063 - val_loss: 1.7986 - val_precision_3: 0.5948 - val_recall_3: 0.6379\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5198 - precision_3: 0.6112 - recall_3: 0.6100 - val_loss: 1.9299 - val_precision_3: 0.7909 - val_recall_3: 0.3712\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5619 - precision_3: 0.6090 - recall_3: 0.6089 - val_loss: 1.8614 - val_precision_3: 0.7367 - val_recall_3: 0.5749\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.4358 - precision_3: 0.6080 - recall_3: 0.6077 - val_loss: 5.4004 - val_precision_3: 0.5610 - val_recall_3: 0.9379\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5947 - precision_3: 0.6012 - recall_3: 0.6021 - val_loss: 6.6090 - val_precision_3: 0.5417 - val_recall_3: 0.9341\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5984 - precision_3: 0.6058 - recall_3: 0.6074 - val_loss: 2.6764 - val_precision_3: 0.6305 - val_recall_3: 0.7260\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.4398 - precision_3: 0.6062 - recall_3: 0.6055 - val_loss: 5.5839 - val_precision_3: 0.8177 - val_recall_3: 0.0813\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.5883 - precision_3: 0.6083 - recall_3: 0.6046 - val_loss: 4.7206 - val_precision_3: 0.5616 - val_recall_3: 0.8939\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6034 - precision_3: 0.6019 - recall_3: 0.6034 - val_loss: 3.2313 - val_precision_3: 0.7606 - val_recall_3: 0.4059\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.3488 - precision_3: 0.6096 - recall_3: 0.6070 - val_loss: 5.4352 - val_precision_3: 0.7998 - val_recall_3: 0.4052\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on X_test using the best model\n",
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>9330</td>\n",
       "      <td>1047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>6140</td>\n",
       "      <td>4183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         9330         1047\n",
       "Actual 1         6140         4183"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building confusion matrix\n",
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.28%\n",
      "Precision: 79.98%\n",
      "Recall: 40.52%\n",
      "F1_score: 53.79%\n"
     ]
    }
   ],
   "source": [
    "#evaluating performance of the best single layer model\n",
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with two hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building neural network with two hidden layer and performing hyperparameter tuning\n",
    "def two_layer_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256,512])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  \n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  \n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3]) \n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    two_layer_model,\n",
    "    objective=['val_recall','val_precision'],  # Optimize for recall\n",
    "    max_epochs= 20,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Two hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 Complete [00h 01m 31s]\n",
      "multi_objective: -1.5081620812416077\n",
      "\n",
      "Best multi_objective So Far: -1.5120445489883423\n",
      "Total elapsed time: 00h 31m 34s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=20,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 128\n",
      "- Layer 1 Activation: leaky_relu\n",
      "- Layer 1 Dropout: 0.3\n",
      "- Layer 2 Units: 128\n",
      "- Layer 2 Activation: relu\n",
      "- Layer 2 Dropout: 0.2\n",
      "- Optimizer: rmsprop\n",
      "- Learning Rate: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 1 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 3.0526 - precision_3: 0.5476 - recall_3: 0.4310 - val_loss: 0.6970 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.7025 - precision_3: 0.4908 - recall_3: 0.3889 - val_loss: 0.6949 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.7245 - precision_3: 0.4964 - recall_3: 0.4027 - val_loss: 0.6958 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.7592 - precision_3: 0.4935 - recall_3: 0.4428 - val_loss: 0.6962 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.7007 - precision_3: 0.4947 - recall_3: 0.4353 - val_loss: 0.6933 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6995 - precision_3: 0.4970 - recall_3: 0.4071 - val_loss: 0.6947 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6956 - precision_3: 0.4924 - recall_3: 0.4236 - val_loss: 0.6974 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6965 - precision_3: 0.4879 - recall_3: 0.4048 - val_loss: 0.6960 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6974 - precision_3: 0.4929 - recall_3: 0.4094 - val_loss: 0.6937 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.8367 - precision_3: 0.4957 - recall_3: 0.3914 - val_loss: 0.6947 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6984 - precision_3: 0.4952 - recall_3: 0.4601 - val_loss: 0.7075 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.7290 - precision_3: 0.4958 - recall_3: 0.4011 - val_loss: 0.6999 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6963 - precision_3: 0.4939 - recall_3: 0.4473 - val_loss: 0.7019 - val_precision_3: 0.7500 - val_recall_3: 0.0012\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6993 - precision_3: 0.4823 - recall_3: 0.3967 - val_loss: 0.6954 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6978 - precision_3: 0.4955 - recall_3: 0.4950 - val_loss: 0.6955 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.7096 - precision_3: 0.4917 - recall_3: 0.4288 - val_loss: 0.6935 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6967 - precision_3: 0.4908 - recall_3: 0.4037 - val_loss: 0.6941 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.6973 - precision_3: 0.5022 - recall_3: 0.4588 - val_loss: 0.6989 - val_precision_3: 0.4987 - val_recall_3: 1.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.6961 - precision_3: 0.4893 - recall_3: 0.4170 - val_loss: 0.6934 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6956 - precision_3: 0.4915 - recall_3: 0.4154 - val_loss: 0.6932 - val_precision_3: 0.0000e+00 - val_recall_3: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>10377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>10323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0        10377            0\n",
       "Actual 1        10323            0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.13%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1_score: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with three hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for Keras Tuner with reduced search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256,512])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    model.add(Dense(hp.Choice('units_3', [32, 64, 128])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_3', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_3', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=['val_recall','val_precision'],  # Optimize for recall\n",
    "    max_epochs=20,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Three hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33 Complete [00h 00m 21s]\n",
      "multi_objective: -1.4699949622154236\n",
      "\n",
      "Best multi_objective So Far: -1.4986956417560577\n",
      "Total elapsed time: 00h 09m 46s\n",
      "\n",
      "Search: Running Trial #34\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "512               |128               |units_1\n",
      "relu              |leaky_relu        |activation_1\n",
      "0.3               |0.3               |dropout_1\n",
      "64                |64                |units_2\n",
      "relu              |leaky_relu        |activation_2\n",
      "0.1               |0.3               |dropout_2\n",
      "64                |32                |units_3\n",
      "relu              |relu              |activation_3\n",
      "0.1               |0.1               |dropout_3\n",
      "adam              |adam              |optimizer\n",
      "0.01              |0.1               |learning_rate\n",
      "5                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "1                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/5\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.5808 - precision: 0.7257 - recall: 0.6834 - val_loss: 0.5684 - val_precision: 0.7829 - val_recall: 0.6095\n",
      "Epoch 2/5\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5660 - precision: 0.7472 - recall: 0.6750 - val_loss: 0.5575 - val_precision: 0.7714 - val_recall: 0.6296\n",
      "Epoch 3/5\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5616 - precision: 0.7303 - recall: 0.7068 - val_loss: 0.5666 - val_precision: 0.7625 - val_recall: 0.6378\n",
      "Epoch 4/5\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5660 - precision: 0.7312 - recall: 0.6863 - val_loss: 0.5568 - val_precision: 0.7295 - val_recall: 0.7138\n",
      "Epoch 5/5\n",
      "\u001b[1m1509/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5627 - precision: 0.7376 - recall: 0.6884"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Define Early Stopping callback\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# early_stopping = EarlyStopping(\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     monitor='val_recall',  # Stop training if recall doesn't improve\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced number of epochs\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;66;43;03m#callbacks=[early_stopping],  # Use Early Stopping\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    242\u001b[0m     ):\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    255\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py:427\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    425\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    426\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtuner/initial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:395\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    386\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    387\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    394\u001b[0m     )\n\u001b[1;32m--> 395\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    407\u001b[0m }\n\u001b[0;32m    408\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:483\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    482\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m--> 483\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Shivam\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=20,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 1 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Layer 3 Units: {best_hps.get('units_3')}\n",
    "- Layer 3 Activation: {best_hps.get(f'activation_3')}\n",
    "- Layer 3 Dropout: {best_hps.get('dropout_3')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
