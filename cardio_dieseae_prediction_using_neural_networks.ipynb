{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433834</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443711</td>\n",
       "      <td>-0.845741</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.309613</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>0.759448</td>\n",
       "      <td>0.771644</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.245845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>-0.706160</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.745799</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.550076</td>\n",
       "      <td>1.335923</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.806166</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>-1.264486</td>\n",
       "      <td>-1.485474</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.992694</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.628408</td>\n",
       "      <td>-0.496787</td>\n",
       "      <td>-0.356915</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.073318</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897072</td>\n",
       "      <td>1.317775</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.662604</td>\n",
       "      <td>1.457357</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.727567</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.775183</td>\n",
       "      <td>-0.217624</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>-0.426996</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    height    weight     ap_hi     ap_lo  cholesterol  \\\n",
       "0 -0.433834       2  0.443711 -0.845741 -0.921194 -0.134931            1   \n",
       "1  0.309613       1 -1.018961  0.759448  0.771644  0.877460            3   \n",
       "2 -0.245845       1  0.078043 -0.706160  0.207365 -1.147322            3   \n",
       "3 -0.745799       2  0.565600  0.550076  1.335923  1.889851            1   \n",
       "4 -0.806166       1 -1.018961 -1.264486 -1.485474 -2.159713            1   \n",
       "5  0.992694       1 -1.628408 -0.496787 -0.356915 -0.134931            2   \n",
       "6  1.073318       1 -0.897072  1.317775  0.207365 -0.134931            3   \n",
       "7  1.264143       2  1.662604  1.457357  0.207365  0.877460            3   \n",
       "8 -0.727567       1 -0.775183 -0.217624 -0.921194 -1.147322            1   \n",
       "9  0.149985       1 -0.043847 -0.426996 -0.921194 -2.159713            1   \n",
       "\n",
       "   gluc  smoke  active  cardio  \n",
       "0     1      0       1       0  \n",
       "1     1      0       1       1  \n",
       "2     1      0       0       1  \n",
       "3     1      0       1       1  \n",
       "4     1      0       0       0  \n",
       "5     2      0       0       0  \n",
       "6     1      0       1       0  \n",
       "7     3      0       1       1  \n",
       "8     1      0       1       0  \n",
       "9     1      0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the preprocessed data\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into trainning and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"cardio\"],axis=1)\n",
    "y = df[\"cardio\"].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQPlJREFUeJzt3QmUVdWZL/CPQQYHwAmQiGg0cQIhgiIOtAMPHGJLNLYDUZwwGjFRfKLkGZyS0IIDqERajdOLtGg6aESDEhBHnFDiTKvBJ4kiJopElLne2rv73q5iFKlDVcHvt9bJrXPOrnNP1Qru+t+9z7frVVRUVAQAAABQ7epX/yUBAACAROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AaqxSmnnBLbb799Td8GAADUKkI3rOfq1av3lbbJkydHbfPee+/FqaeeGjvuuGM0adIkWrduHd27d49LL730a13v4Ycfjssuu6za7xMA6nL//cUXX+T+cU2upY+Gr65eRUVFxRq0B+qY3/zmN1X277rrrpgwYUL83//7f6sc/1//639Fq1atvvb7LFq0KJYuXRqNGzeO6vDOO+/EXnvtFU2bNo3TTjstj6J/+OGH8dJLL8Uf/vCHmD9//hpfs3///jFy5Mjwnz0Aart11X8nf/vb32LrrbfOgfmrBF99NKyZhmvYHqhjfvCDH1TZf/bZZ3OnvezxFX3qvfHGG3/l99loo42iOl133XXx+eefx7Rp06Jdu3ZVzs2ePbta3wsA1pf+e13QR8OaMb0ciAMPPDDat28fU6dOzVPDUtj+6U9/ms898MADccQRR0SbNm3yKHaaRnbllVfGkiVLVvlMd5p2lqa9XX311XHzzTfn70vfnz4Zf+GFF1Z7T++++25su+22y3XmScuWLZc7lj5ZP+CAA2KTTTaJzTbbLN/z66+/XuX+0ifoSeVpeQBQV6UZZsOHD4/dd989T/FOI94//OEP49NPP63S7sUXX4xevXrFVlttlUend9hhhzxCXeqv0yh3cvnll5f7x1WNeOujYc0Y6Qayv//973HYYYfF8ccfnz9FL01Vu+OOO2LTTTeNAQMG5NdJkybF4MGDY+7cuTFs2LDVXnf06NHxj3/8I/8RkDrQoUOHxtFHHx1//vOfVzk6njryP/7xj/n9Dj744FW+R5pq17dv3/wHxVVXXZVH6W+66abYf//94+WXX84fBqT3/+CDD1Y4NQ8A6qLUt6V+Oj1b/eMf/zhmzJgRN954Y+77nn766dzPppHnnj175mB98cUXR4sWLXLQ/t3vfpevkY6nPvPss8+O733ve7mPTvbYY4+Vvq8+GtZQeqYb2HCcc8456WGpKsf+6Z/+KR8bNWrUcu2/+OKL5Y798Ic/rNh4440r5s+fXz7Wt2/finbt2pX3Z8yYka+55ZZbVnzyySfl4w888EA+/uCDD67yPl977bWKpk2b5radOnWq+MlPflJx//33V8ybN69Ku3/84x8VLVq0qOjXr1+V47Nmzapo3rx5leMr+tkBoC5Ytg978skn8/7dd99dpd348eOrHB87dmzef+GFF1Z67Y8//ji3ufTSS7/SveijYc2YXg5kaep3+qR8WWkaWkkasU7FVtIUsfRJ9VtvvbXa6x533HGx+eabl/fT9yZppHtV0lS59KxYGnVPn8iPGDEievfunUfgb7nllnK79Kn4nDlz4oQTTsj3VtoaNGgQXbt2jccee+wr/w4AoK647777onnz5rmQWuX+r3PnznlmWqn/SyPbybhx43LR0+qgj4Y1Y3o5kH3jG9+IRo0aLXc8PXN1ySWX5ClkaUp5ZZ999tlqr7vddttV2S8F8GWfN1uRb3/723maWXp+/I033sh/MKTp6WeeeWZ+Hq1Hjx7x9ttv57Yrm97WrFmz1b4PANQ1qf9L/fCKnqGuXNDsn/7pn+KYY47Jz2unAmipjksKyCeeeOJarTiij4avTugGlhvRLkmfTqfOOnWKV1xxRXktzrQkyEUXXZQLuKxO+jR7RdZkSZB0jQ4dOuStW7ducdBBB8Xdd9+dO/TSPaSOP60RuqyGDf1nDoD1T+r/UuBO/eGKlIqjpXoqv/3tb3P18wcffDAeeeSRXETtmmuuycfSqPja0EfD6vl/OrBSkydPzgXWUrGVVNW8JBVqqSldunTJr2k90CR9EJCkPzxSB78qKqECsL5I/V8qZrbffvut8IPzZe2zzz55+8UvfpGLnPbp0yfuueeeOOOMM6qtf9RHw4p5phtY7Sh15VHphQsXxq9+9avC3/vJJ59c4bNnDz/8cH7deeed82uqhppG4n/5y1+usP3HH39c/jotVVIawQeAuuxf/uVf8tTutIznshYvXlzu69LjXMvOLuvUqVN+XbBgQX5NS4WuSf+oj4Y1Y6QbWKl99903P4OdlvpIS5GkT6HTFLE1mRr+daVlRdK64WnpktKyJWla+1133RVbbLFFnHfeeflY6szT0iMnnXRS7LnnnnnJszSl7v3334+HHnoojwCk5VOSVFwmST9L+kMgfaiQ2gNAXZMe/0pLbQ0ZMiQXNUvLgqUlwtJz1KnIWipu9v3vfz/uvPPO/GF5Wg4sjTynoqip2FnqPw8//PB8rTRSvttuu8WYMWPys9qpn23fvn3eVkQfDWtoDaudA+vpkmG77777Cts//fTTFfvss09eGqRNmzYVAwcOrHjkkUfyNR577LHVLhk2bNiw5a75VZYlSe+b7rV9+/Z5WZGNNtqoYrvttqs45ZRTKt59993l2qd76dWrV27bpEmTih133DG3ffHFF8ttFi9eXHHuuedWbL311hX16tWzNAkAdcbKltS6+eabKzp37pz76c0226yiQ4cOua/+4IMP8vmXXnqp4oQTTsh9aOPGjStatmxZ8d3vfrdK/5g888wz+TqNGjVabT+tj4Y1Uy/9z5oGdQAAAGD1PNMNAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACtKwqAtvaJYuXRoffPBBbLbZZlGvXr2avh0A6rC0muc//vGPaNOmTdSv7/Px6qbPBmBd9tdCdzVJnXfbtm1r+jYAWI/MnDkztt1225q+jfWOPhuAddlfC93VJH1aXvqFN2vWrKZvB4A6bO7cuTkUlvoWqpc+G4B12V8L3dWkND0tdd46cACqg6nPxdBnA7Au+2sPigEAAEBBhG4AAAAoiNANAAAA62PoHjJkSOy11175wfOWLVtG7969Y/r06VXaHHjggXmOfOXtrLPOqtLm/fffjyOOOCI23njjfJ0LL7wwFi9eXKXN5MmTY88994zGjRvHTjvtFHfcccdy9zNy5MjYfvvto0mTJtG1a9d4/vnnC/rJAQAA2BDUaOh+/PHH45xzzolnn302JkyYEIsWLYqePXvGvHnzqrTr169ffPjhh+Vt6NCh5XNLlizJgXvhwoXxzDPPxJ133pkD9eDBg8ttZsyYkdscdNBBMW3atDjvvPPijDPOiEceeaTcZsyYMTFgwIC49NJL46WXXoqOHTtGr169Yvbs2evotwEAAMD6pl5FWtG7lvj444/zSHUK4927dy+PdHfq1CmGDx++wu/5wx/+EN/97nfzmputWrXKx0aNGhUXXXRRvl6jRo3y1w899FC89tpr5e87/vjjY86cOTF+/Pi8n0a206j7jTfemPeXLl2ay7+fe+65cfHFF3+lcvHNmzePzz77TCVUANaKPqVYfr8ArMv+pFY9051uNtliiy2qHL/77rtjq622ivbt28egQYPiiy++KJ+bMmVKdOjQoRy4kzRCnX4Br7/+erlNjx49qlwztUnHkzRKPnXq1Cpt6tevn/dLbQAAAGBN1Zp1utPIcpr2vd9+++VwXXLiiSdGu3btok2bNvHKK6/kUev03Pfvfve7fH7WrFlVAndS2k/nVtUmBfMvv/wyPv300zxNfUVt3nrrrRXe74IFC/JWkq4FAAAAtTJ0p2e70/Tvp556qsrxM888s/x1GtHeZptt4pBDDol33303dtxxx6jJInCXX355jb0/AAAAtV+tmF7ev3//GDduXDz22GOx7bbbrrJtevY6eeedd/Jr69at46OPPqrSprSfzq2qTZp337Rp0zx1vUGDBitsU7rGstI09zQdvrTNnDlzjX9uAAAA1m81GrpTDbcUuMeOHRuTJk2KHXbYYbXfk6qPJ2nEO+nWrVu8+uqrVaqMp0roKVDvtttu5TYTJ06scp3UJh1PUrG1zp07V2mTprun/VKbZaWlx9J7VN4AAACg1kwvT1PKR48eHQ888EBeq7v0DHaqAJdGoNMU8nT+8MMPjy233DI/033++efnyuZ77LFHbpuWGEvh+qSTTspLiaVrXHLJJfnaKRgnaV3vVJV84MCBcdppp+WAf++99+aK5iVpubC+fftGly5dYu+9987V0tPSZaeeemoN/XYAAACo62o0dN90003lZcEqu/322+OUU07JI9B//OMfywE4LeF1zDHH5FBdkqaFp6npZ599dh6V3mSTTXJ4vuKKK8pt0gh6CtgpsI8YMSJPYb/11ltzBfOS4447Li8xltb3TsE9LVOWlhNbtrgaAAAA1Ml1uusya34CUF30KcXy+wVgg12nGwAAANYnQjcAAAAUROgGAACA9bGQGqvW+cK7avoWIKYOO7mmbwGg1tNnUxvos6F2MtINAAAABRG6AQAAoCBCNwAAABTEM90AAEDh1D5gQ619YKQbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFUUgNqPMUZmFDLMoCANQNRroBgNV64okn4sgjj4w2bdpEvXr14v77769yvqKiIgYPHhzbbLNNNG3aNHr06BFvv/12lTaffPJJ9OnTJ5o1axYtWrSI008/PT7//PMqbV555ZU44IADokmTJtG2bdsYOnTocvdy3333xS677JLbdOjQIR5++OGCfmoAWHtCNwCwWvPmzYuOHTvGyJEjV3g+hePrr78+Ro0aFc8991xssskm0atXr5g/f365TQrcr7/+ekyYMCHGjRuXg/yZZ55ZPj937tzo2bNntGvXLqZOnRrDhg2Lyy67LG6++eZym2eeeSZOOOGEHNhffvnl6N27d95ee+21gn8DAPD1mF4OAKzWYYcdlrcVSaPcw4cPj0suuSSOOuqofOyuu+6KVq1a5RHx448/Pt58880YP358vPDCC9GlS5fc5oYbbojDDz88rr766jyCfvfdd8fChQvjtttui0aNGsXuu+8e06ZNi2uvvbYczkeMGBGHHnpoXHjhhXn/yiuvzCH+xhtvzIEfAGobI90AwFqZMWNGzJo1K08pL2nevHl07do1pkyZkvfTa5pSXgrcSWpfv379PDJeatO9e/ccuEvSaPn06dPj008/Lbep/D6lNqX3AYDaxkg3ALBWUuBO0sh2ZWm/dC69tmzZssr5hg0bxhZbbFGlzQ477LDcNUrnNt988/y6qvdZkQULFuSt8jR2AFhXjHQDAOu1IUOG5JH30pYKtAHAuiJ0AwBrpXXr1vn1o48+qnI87ZfOpdfZs2dXOb948eJc0bxymxVdo/J7rKxN6fyKDBo0KD777LPyNnPmzLX4aQFgzQjdAMBaSVPCU+idOHFilSnc6Vntbt265f30OmfOnFyVvGTSpEmxdOnS/Ox3qU2qaL5o0aJym1Qkbeedd85Ty0ttKr9PqU3pfVakcePGeZmyyhsArCtCNwCwWmk97VRJPG2l4mnp6/fffz+v233eeefFz3/+8/j9738fr776apx88sm5InlazivZddddc9Xxfv36xfPPPx9PP/109O/fP1c2T+2SE088MRdRS8uBpaXFxowZk6uVDxgwoHwfP/nJT3IV9GuuuSbeeuutvKTYiy++mK8FALWRQmoAwGqlYHvQQQeV90tBuG/fvnHHHXfEwIED81reaWmvNKK9//7753DcpEmT8vekJcFSOD7kkENy1fJjjjkmr+1dkp63fvTRR+Occ86Jzp07x1ZbbRWDBw+uspb3vvvuG6NHj87Lk/30pz+Nb33rW3lZsvbt26+z3wUArAmhGwBYrQMPPDCvx70yabT7iiuuyNvKpErlKTCvyh577BFPPvnkKtsce+yxeQOAusD0cgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAAKyPoXvIkCGx1157xWabbRYtW7aM3r17x/Tp06u0mT9/fpxzzjmx5ZZbxqabbhrHHHNMfPTRR1XavP/++3HEEUfExhtvnK9z4YUXxuLFi6u0mTx5cuy5557RuHHj2GmnneKOO+5Y7n5GjhwZ22+/fTRp0iS6du0azz//fEE/OQAAABuCGg3djz/+eA7Uzz77bEyYMCEWLVoUPXv2jHnz5pXbnH/++fHggw/Gfffdl9t/8MEHcfTRR5fPL1myJAfuhQsXxjPPPBN33nlnDtSDBw8ut5kxY0Zuc9BBB8W0adPivPPOizPOOCMeeeSRcpsxY8bEgAED4tJLL42XXnopOnbsGL169YrZs2evw98IAAAA65OGNfnm48ePr7KfwnIaqZ46dWp07949Pvvss/j1r38do0ePjoMPPji3uf3222PXXXfNQX2fffaJRx99NN5444344x//GK1atYpOnTrFlVdeGRdddFFcdtll0ahRoxg1alTssMMOcc011+RrpO9/6qmn4rrrrsvBOrn22mujX79+ceqpp+b99D0PPfRQ3HbbbXHxxRev898NAAAAdV+teqY7hexkiy22yK8pfKfR7x49epTb7LLLLrHddtvFlClT8n567dChQw7cJSlIz507N15//fVym8rXKLUpXSONkqf3qtymfv36eb/UBgAAAOrUSHdlS5cuzdO+99tvv2jfvn0+NmvWrDxS3aJFiyptU8BO50ptKgfu0vnSuVW1ScH8yy+/jE8//TRPU19Rm7feemuF97tgwYK8laRrAQAAQK0c6U7Pdr/22mtxzz33RF2QisA1b968vLVt27ambwkAAIBaplaE7v79+8e4cePisccei2233bZ8vHXr1nnq95w5c6q0T9XL07lSm2WrmZf2V9emWbNm0bRp09hqq62iQYMGK2xTusayBg0alKfDl7aZM2eu1e8AAACA9U+Nhu6KioocuMeOHRuTJk3Kxc4q69y5c2y00UYxceLE8rG0pFhaIqxbt255P72++uqrVaqMp0roKVDvtttu5TaVr1FqU7pGmsKe3qtymzTdPe2X2iwrLT2W3qPyBgAAALXmme40pTxVJn/ggQfyWt2lZ7DTdO00Ap1eTz/99LyUVyquloLtueeem4NwqlyepCXGUrg+6aSTYujQofkal1xySb52CsbJWWedFTfeeGMMHDgwTjvttBzw77333lydvCS9R9++faNLly6x9957x/Dhw/PSZaVq5gAAAFCnQvdNN92UXw888MAqx9OyYKecckr+Oi3rlSqJH3PMMblwWao6/qtf/arcNk0LT1PTzz777BzGN9lkkxyer7jiinKbNIKeAnZa83vEiBF5Cvutt95aXi4sOe644+Ljjz/O63un4J6WHktLmi1bXA0AAADqROhO08tXp0mTJjFy5Mi8rUy7du3i4YcfXuV1UrB/+eWXV9kmTXVPGwAAAKw3hdQAAABgfSR0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAWGtLliyJn/3sZ7HDDjtE06ZNY8cdd4wrr7wyKioqym3S14MHD45tttkmt+nRo0e8/fbbVa7zySefRJ8+faJZs2bRokWLOP300+Pzzz+v0uaVV16JAw44IJo0aRJt27aNoUOHrrOfEwDWlNANAKy1q666Km666aa48cYb480338z7KQzfcMMN5TZp//rrr49Ro0bFc889F5tsskn06tUr5s+fX26TAvfrr78eEyZMiHHjxsUTTzwRZ555Zvn83Llzo2fPntGuXbuYOnVqDBs2LC677LK4+eab1/nPDABfRcOv1AoAYBWeeeaZOOqoo+KII47I+9tvv338+7//ezz//PPlUe7hw4fHJZdcktsld911V7Rq1Sruv//+OP7443NYHz9+fLzwwgvRpUuX3CaF9sMPPzyuvvrqaNOmTdx9992xcOHCuO2226JRo0ax++67x7Rp0+Laa6+tEs4BoLYw0g0ArLV99903Jk6cGP/5n/+Z9//0pz/FU089FYcddljenzFjRsyaNStPKS9p3rx5dO3aNaZMmZL302uaUl4K3ElqX79+/TwyXmrTvXv3HLhL0mj59OnT49NPP11nPy8AfFVGugGAtXbxxRfnqd+77LJLNGjQID/j/Ytf/CJPF09S4E7SyHZlab90Lr22bNmyyvmGDRvGFltsUaVNem582WuUzm2++ebL3duCBQvyVpLuEwDWFSPdAMBau/fee/PU79GjR8dLL70Ud955Z54Snl5r2pAhQ/KoemlLxdcAYF0RugGAtXbhhRfm0e70bHaHDh3ipJNOivPPPz8H3qR169b59aOPPqryfWm/dC69zp49u8r5xYsX54rmldus6BqV32NZgwYNis8++6y8zZw5s9p+bgBYHaEbAFhrX3zxRX72urI0zXzp0qX56zQlPIXi9Nx35Wne6Vntbt265f30OmfOnFyVvGTSpEn5GunZ71KbVNF80aJF5Tap0vnOO++8wqnlSePGjfMSZJU3AFhXhG4AYK0deeSR+Rnuhx56KN57770YO3Zsrij+ve99L5+vV69enHfeefHzn/88fv/738err74aJ598cq5I3rt379xm1113jUMPPTT69euXq54//fTT0b9//zx6ntolJ554Yi6iltbvTkuLjRkzJkaMGBEDBgyo0Z8fAFZGITUAYK2lpb1+9rOfxY9+9KM8RTyF5B/+8IcxePDgcpuBAwfGvHnz8tJeaUR7//33z0uENWnSpNwmPReegvYhhxySR86POeaYvLZ3SXom+9FHH41zzjknOnfuHFtttVV+D8uFAVBbCd0AwFrbbLPN8jrcaVuZNNp9xRVX5G1lUqXyVIxtVfbYY4948skn1+p+AWBdMb0cAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAA1sfQ/cQTT8SRRx4Zbdq0iXr16sX9999f5fwpp5ySj1feDj300CptPvnkk+jTp080a9YsWrRoEaeffnp8/vnnVdq88sorccABB0STJk2ibdu2MXTo0OXu5b777otddtklt+nQoUM8/PDDBf3UAAAAbChqNHTPmzcvOnbsGCNHjlxpmxSyP/zww/L27//+71XOp8D9+uuvx4QJE2LcuHE5yJ955pnl83Pnzo2ePXtGu3btYurUqTFs2LC47LLL4uabby63eeaZZ+KEE07Igf3ll1+O3r175+21114r6CcHAABgQ9CwJt/8sMMOy9uqNG7cOFq3br3Cc2+++WaMHz8+XnjhhejSpUs+dsMNN8Thhx8eV199dR5Bv/vuu2PhwoVx2223RaNGjWL33XePadOmxbXXXlsO5yNGjMjh/sILL8z7V155ZQ7xN954Y4waNaraf24AAAA2DLX+me7JkydHy5YtY+edd46zzz47/v73v5fPTZkyJU8pLwXupEePHlG/fv147rnnym26d++eA3dJr169Yvr06fHpp5+W26Tvqyy1ScdXZsGCBXkUvfIGAAAAdSZ0p9Hnu+66KyZOnBhXXXVVPP7443lkfMmSJfn8rFmzciCvrGHDhrHFFlvkc6U2rVq1qtKmtL+6NqXzKzJkyJBo3rx5eUvPigMAAECtmV6+Oscff3z561TcbI899ogdd9wxj34fcsghNXpvgwYNigEDBpT300i34A0AAECdGele1je/+c3Yaqut4p133sn76Vnv2bNnV2mzePHiXNG89Bx4ev3oo4+qtCntr67Nyp4lLz1rniqmV94AAACgzobuv/zlL/mZ7m222Sbvd+vWLebMmZOrkpdMmjQpli5dGl27di23SRXNFy1aVG6TiqSlZ8Q333zzcps0hb2y1CYdBwAAgDoZutN62qmSeNqSGTNm5K/ff//9fC5VE3/22Wfjvffey6H4qKOOip122ikXOUt23XXX/Nx3v3794vnnn4+nn346+vfvn6elp8rlyYknnpiLqKXlwNLSYmPGjMnVyitPDf/JT36Sq6Bfc8018dZbb+UlxV588cV8LQAAAKiToTsF2+985zt5S1IQTl8PHjw4GjRoEK+88kr88z//c3z729/Ooblz587x5JNP5qndJWlJsF122SU/452WCtt///2rrMGdipw9+uijOdCn77/gggvy9Suv5b3vvvvG6NGj8/eldcN/+9vfxv333x/t27dfx78RAAAA1ic1WkjtwAMPjIqKipWef+SRR1Z7jVSpPAXmVUkF2FJYX5Vjjz02bwAAALBBPtMNAAAAdYnQDQAAAAURugEAAKAgQjcAUC3++te/xg9+8IPYcssto2nTptGhQ4dcNLUk1XFJxUzT0p/pfI8ePeLtt9+uco1PPvkk+vTpE82aNYsWLVrkQqppRZPKUqHVAw44IJo0aRJt27aNoUOHrrOfEQDWlNANAKy1Tz/9NPbbb7/YaKON4g9/+EO88cYbeSnOzTffvNwmhePrr78+Ro0aFc8991xssskmeRnQ+fPnl9ukwJ2W+JwwYUKMGzcunnjiiSorjsydOzd69uwZ7dq1i6lTp8awYcPyUp+VVy4BgNqkRquXAwDrh6uuuiqPOt9+++3lYzvssEOVUe7hw4fHJZdcEkcddVQ+dtddd0WrVq3yMp3HH398vPnmmzF+/Ph44YUXokuXLrnNDTfckJcEvfrqq6NNmzZ5qdCFCxfGbbfdFo0aNYrdd989pk2bFtdee22VcA4AtYWRbgBgrf3+97/PQTktv9myZcv4zne+E7fcckv5/IwZM2LWrFl5SnlJ8+bNo2vXrjFlypS8n17TlPJS4E5S+/r16+eR8VKb7t2758BdkkbLp0+fnkfbAaC2EboBgLX25z//OW666ab41re+FY888kicffbZ8eMf/zjuvPPOfD4F7iSNbFeW9kvn0msK7JU1bNgwtthiiyptVnSNyu+xrAULFuRp6ZU3AFhXTC8HANba0qVL8wj1L3/5y7yfRrpfe+21/Px23759a/TehgwZEpdffnmN3gMAGy4j3QDAWksVyXfbbbcqx3bdddd4//3389etW7fOrx999FGVNmm/dC69zp49u8r5xYsX54rmldus6BqV32NZgwYNis8++6y8zZw5cy1/WgAoOHQffPDBMWfOnOWOp+la6RwAUPPWZX+dKpen56or+8///M9cZbxUVC2F4okTJ1a5j/Ssdrdu3fJ+ek33m6qSl0yaNCmPoqdnv0ttUkXzRYsWldukSuc777xzlUrplTVu3DgvQVZ5A4BaHbonT56cK4cuKy358eSTT1bHfQEAa2ld9tfnn39+PPvss3l6+TvvvBOjR4/Oy3idc845+Xy9evXivPPOi5///Oe56Nqrr74aJ598cq5I3rt37/LI+KGHHhr9+vWL559/Pp5++uno379/rmye2iUnnnhiLqKW1u9OS4uNGTMmRowYEQMGDKjWnwcAauSZ7ldeeaX8dVp/s3LBkiVLluRlPr7xjW9U280BAGuuJvrrvfbaK8aOHZuncl9xxRV5ZDstEZbW3S4ZOHBgzJs3Ly/tlUa0999//3wvTZo0KbdJS4KloH3IIYfkquXHHHNMXtu7csXzRx99NIf5zp07x1ZbbRWDBw+2XBgA60fo7tSpU/6kOm0rmpbWtGnTvJ4mAFBzaqq//u53v5u3lUn3kwJ52lYmVSpPo+Srsscee5hZB8D6GbrTGpsVFRXxzW9+M0/72nrrrcvn0lSvtMxHgwYNirhPAOAr0l8DQB0N3aViKKmgCQBQO+mvAWA9WKf77bffjsceeywv7bFsp56erQIAap7+GgDqYOi+5ZZb4uyzz87FS9LyH+kZrZL0tU4cAGqe/hoA6mjoTst9/OIXv4iLLrqo+u8IAKgW+msAqKPrdH/66adx7LHHVv/dAADVRn8NAHU0dKcOPK2RCQDUXvprAKij08t32mmn+NnPfhbPPvtsdOjQITbaaKMq53/84x9X1/0BAF+T/hoA6mjovvnmm2PTTTeNxx9/PG+VpcIsOnEAqHn6awCoo6F7xowZ1X8nAEC10l8DQB19phsAAAAoaKT7tNNOW+X522677etcFgCoRvprAKijoTstQVLZokWL4rXXXos5c+bEwQcfXF33BgCsBf01ANTR0D127Njlji1dujTOPvvs2HHHHavjvgCAtaS/BoD16Jnu+vXrx4ABA+K6666rrksCANVMfw0AdbiQ2rvvvhuLFy+uzksCANVMfw0AtXx6efqEvLKKior48MMP46GHHoq+fftW170BAGtBfw0AdTR0v/zyy8tNVdt6663jmmuuWW2lVABg3dBfA0AdDd2PPfZY9d8JAFCt9NcAUEdDd8nHH38c06dPz1/vvPPO+dNzAKB20V8DQB0rpDZv3rw8LW2bbbaJ7t27561NmzZx+umnxxdffFH9dwkArDH9NQDU0dCdCrM8/vjj8eCDD8acOXPy9sADD+RjF1xwQfXfJQCwxvTXAFBHp5f/x3/8R/z2t7+NAw88sHzs8MMPj6ZNm8a//Mu/xE033VSd9wgAfA36awCooyPdaUpaq1atljvesmVL09UAoJbQXwNAHQ3d3bp1i0svvTTmz59fPvbll1/G5Zdfns8BADVPfw0AdXR6+fDhw+PQQw+NbbfdNjp27JiP/elPf4rGjRvHo48+Wt33CAB8DfprAKijobtDhw7x9ttvx9133x1vvfVWPnbCCSdEnz598nNiAEDN018DQB0N3UOGDMnPiPXr16/K8dtuuy2vBXrRRRdV1/0BAF+T/hoA6ugz3f/2b/8Wu+yyy3LHd9999xg1alR13BcAsJb01wBQR0P3rFmzYptttlnu+NZbbx0ffvhhddwXALCW9NcAUEdDd9u2bePpp59e7ng61qZNm+q4LwBgLemvAaCOPtOdng0777zzYtGiRXHwwQfnYxMnToyBAwfGBRdcUN33CAB8DfprAKijofvCCy+Mv//97/GjH/0oFi5cmI81adIkF2QZNGhQdd8jAPA16K8BoI6G7nr16sVVV10VP/vZz+LNN9/My45861vfyut+AgC1g/4aAOpo6C7ZdNNNY6+99qq+uwEAqp3+GgDqWCE1AAAAYPWEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAA62PofuKJJ+LII4+MNm3aRL169eL++++vcr6ioiIGDx4c22yzTTRt2jR69OgRb7/9dpU2n3zySfTp0yeaNWsWLVq0iNNPPz0+//zzKm1eeeWVOOCAA6JJkybRtm3bGDp06HL3ct9998Uuu+yS23To0CEefvjhgn5qAAAANhQ1GrrnzZsXHTt2jJEjR67wfArH119/fYwaNSqee+652GSTTaJXr14xf/78cpsUuF9//fWYMGFCjBs3Lgf5M888s3x+7ty50bNnz2jXrl1MnTo1hg0bFpdddlncfPPN5TbPPPNMnHDCCTmwv/zyy9G7d++8vfbaawX/BgAAAFifNazJNz/ssMPytiJplHv48OFxySWXxFFHHZWP3XXXXdGqVas8In788cfHm2++GePHj48XXnghunTpktvccMMNcfjhh8fVV1+dR9DvvvvuWLhwYdx2223RqFGj2H333WPatGlx7bXXlsP5iBEj4tBDD40LL7ww71955ZU5xN9444058AMAAMB69Uz3jBkzYtasWXlKeUnz5s2ja9euMWXKlLyfXtOU8lLgTlL7+vXr55HxUpvu3bvnwF2SRsunT58en376ablN5fcptSm9z4osWLAgj6JX3gAAAKBOhO4UuJM0sl1Z2i+dS68tW7ascr5hw4axxRZbVGmzomtUfo+VtSmdX5EhQ4bkDwFKW3pWHAAAAOpE6K7tBg0aFJ999ll5mzlzZk3fEgAAALVMrQ3drVu3zq8fffRRleNpv3Quvc6ePbvK+cWLF+eK5pXbrOgald9jZW1K51ekcePGuWJ65Q0AAADqROjeYYcdcuidOHFi+Vh6bjo9q92tW7e8n17nzJmTq5KXTJo0KZYuXZqf/S61SRXNFy1aVG6TiqTtvPPOsfnmm5fbVH6fUpvS+wAAAECdC91pPe1USTxtpeJp6ev3338/r9t93nnnxc9//vP4/e9/H6+++mqcfPLJuSJ5Ws4r2XXXXXPV8X79+sXzzz8fTz/9dPTv3z9XNk/tkhNPPDEXUUvLgaWlxcaMGZOrlQ8YMKB8Hz/5yU9yFfRrrrkm3nrrrbyk2IsvvpivBQAAAHUydKdg+53vfCdvSQrC6evBgwfn/YEDB8a5556bl/baa6+9ckhP4bhJkybla6QlwXbZZZc45JBD8lJh+++/f5U1uFORs0cffTQH+s6dO8cFF1yQr195Le999903Ro8enb8vrRv+29/+Ni9L1r59+3X6+wCA9cW//uu/lj9AL5k/f36cc845seWWW8amm24axxxzzHKPd6UP3o844ojYeOONc7HUtJxnenSsssmTJ8eee+6ZH/Xaaaed4o477lhnPxcA1Kl1ug888MC8HvfKpM76iiuuyNvKpErlKTCvyh577BFPPvnkKtsce+yxeQMA1s4LL7wQ//Zv/5b738rOP//8eOihh+K+++7LH4qnGWVHH310nqmWLFmyJAfu9HjZM888Ex9++GGe5bbRRhvFL3/5y9wmfYie2px11ln5g/f0eNgZZ5wR22yzTV7uEwBqm1r7TDcAUPekWWl9+vSJW265pVw7JUkrffz617+Oa6+9Ng4++OA8++z222/P4frZZ5/NbdLMtDfeeCN+85vfRKdOneKwww6LK6+8MkaOHBkLFy7MbUaNGpXrvqRHwtJjZim4f//734/rrruuxn5mAFgVoRsAqDZp+ngaie7Ro0eV46noaSpqWvl4ejxsu+22iylTpuT99NqhQ4do1apVuU0avU6FVFNdllKbZa+d2pSuAQC1TY1OLwcA1h/33HNPvPTSS3l6+bJmzZqVC5u2aNGiyvEUsNO5UpvKgbt0vnRuVW1SMP/yyy+jadOmy733ggUL8laS2gLAumKkGwBYazNnzsyrgaTnrCsXPK0NhgwZkp8hL21t27at6VsCYAMidAMAay1NH589e3auKt6wYcO8Pf7443H99dfnr9NodHoue86cOVW+L1UvT4XTkvS6bDXz0v7q2jRr1myFo9zJoEGD8jPlpS19QAAA64rQDQCstbR056uvvhrTpk0rb126dMlF1Upfpyrkqdp4yfTp0/MSYd26dcv76TVdI4X3kgkTJuRAvdtuu5XbVL5GqU3pGiuSlhZL16i8AcC64pluAGCtbbbZZtG+ffsqxzbZZJO8Jnfp+Omnnx4DBgzIy32m4HvuuefmsLzPPvvk8z179szh+qSTToqhQ4fm57cvueSSXJwtBeckLRV24403xsCBA+O0006LSZMmxb333puXIgOA2kjoBgDWibSsV/369eOYY47Jhc1S1fFf/epX5fMNGjSIcePGxdlnn53DeArtffv2jSuuuKLcJi0XlgJ2WvN7xIgRse2228att95qjW4Aai2hGwAoxOTJk6vspwJrac3ttK1Mu3bt4uGHH17ldQ888MB4+eWXq+0+AaBInukGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAACwIYbuyy67LOrVq1dl22WXXcrn58+fH+ecc05sueWWsemmm8YxxxwTH330UZVrvP/++3HEEUfExhtvHC1btowLL7wwFi9eXKXN5MmTY88994zGjRvHTjvtFHfcccc6+xkBAABYf9Xq0J3svvvu8eGHH5a3p556qnzu/PPPjwcffDDuu+++ePzxx+ODDz6Io48+unx+yZIlOXAvXLgwnnnmmbjzzjtzoB48eHC5zYwZM3Kbgw46KKZNmxbnnXdenHHGGfHII4+s858VAACA9UvDqOUaNmwYrVu3Xu74Z599Fr/+9a9j9OjRcfDBB+djt99+e+y6667x7LPPxj777BOPPvpovPHGG/HHP/4xWrVqFZ06dYorr7wyLrroojyK3qhRoxg1alTssMMOcc011+RrpO9Pwf66666LXr16rfOfFwAAgPVHrR/pfvvtt6NNmzbxzW9+M/r06ZOniydTp06NRYsWRY8ePcpt09Tz7bbbLqZMmZL302uHDh1y4C5JQXru3Lnx+uuvl9tUvkapTekaAAAAsF6OdHft2jVPB995553z1PLLL788DjjggHjttddi1qxZeaS6RYsWVb4nBex0LkmvlQN36Xzp3KrapGD+5ZdfRtOmTVd4bwsWLMhbSWoPAAAAdWak+7DDDotjjz029thjjzz6/PDDD8ecOXPi3nvvrelbiyFDhkTz5s3LW9u2bWv6lgCgRvvFvfbaKzbbbLNcuLR3794xffr0Km0UQAVgQ1SrQ/ey0qj2t7/97XjnnXfyc96pQFoK4ZWlzrv0DHh6XbYzL+2vrk2zZs1WOsqdDBo0KD9XXtpmzpxZbT8nANQ1qaBpCtSprsqECRPyI2A9e/aMefPmldsogArAhqhOhe7PP/883n333dhmm22ic+fOsdFGG8XEiRPL59Mn6ukT8m7duuX99Prqq6/G7Nmzy23SHwIpUO+2227lNpWvUWpTusbKpE/X03UqbwCwoRo/fnyccsopedWRjh075rCc+uRUg6VyAdRrr702F0BN/XgqgJrCdQrqSakA6m9+85tc/DTNeEsFUEeOHJmDeFK5AGoqftq/f//4/ve/nwugAkBtVKtD9//+3/87fxL+3nvv5U75e9/7XjRo0CBOOOGEPKX79NNPjwEDBsRjjz2WO/VTTz01h+VUuTxJn7CncH3SSSfFn/70p/wp+CWXXJI/iU+hOTnrrLPiz3/+cwwcODDeeuut+NWvfpWnr6dP4wGAryeF7GSLLbbIrwqgArChqtWF1P7yl7/kgP33v/89tt5669h///3zp+Hp6yR9ql2/fv38TFgqapY63RSaS1JAHzduXJx99tk5jG+yySbRt2/fuOKKK8pt0qflDz30UA7ZI0aMiG233TZuvfVWy4UBwNe0dOnSPO17v/32i/bt2+djNVkAVfFTAGpSrQ7d99xzzyrPN2nSJE85S9vKtGvXLhdgW5UDDzwwXn755a99nwDA/0gzytJKI0899VTUliJvaQUUAKgJtXp6OQBQt6RnrNMss/ToV5o9VlKTBVAVPwWgJgndAMBaq6ioyIF77NixMWnSpPz4VmU1WQBV8VMAalKtnl4OANSdKeWjR4+OBx54IK/VXXoGOxU+TSPQlQugpuJqKfiee+65Ky2AOnTo0HyNFRVAvfHGG3MB1NNOOy0H/FQANdVnAYDayEg3ALDWbrrppjx1O9VJSUt7lrYxY8aU26QCqN/97ndzAdTu3bvnqeK/+93vliuAml5TGP/BD34QJ5988goLoKbR7bQ0WVo6TAFUAGozI90AQLVML18dBVAB2BAZ6QYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQvcyRo4cGdtvv300adIkunbtGs8//3xN3xIAsAz9NQB1hdBdyZgxY2LAgAFx6aWXxksvvRQdO3aMXr16xezZs2v61gCA/6a/BqAuEborufbaa6Nfv35x6qmnxm677RajRo2KjTfeOG677baavjUA4L/prwGoS4Tu/7Zw4cKYOnVq9OjRo3ysfv36eX/KlCk1em8AwH/RXwNQ1zSs6RuoLf72t7/FkiVLolWrVlWOp/233nprufYLFizIW8lnn32WX+fOnVtt97RkwZfVdi34uqrz/9NF8W+F9e3fSel6FRUV1XrdDbG/TvTZbChqe5/t3wnr27+Tr9pfC91f05AhQ+Lyyy9f7njbtm1r5H6gKM1vOKumbwE22H8n//jHP6J58+aFXHtDos9mQ6HPhpr5d7K6/lro/m9bbbVVNGjQID766KMqx9N+69atl2s/aNCgXMSlZOnSpfHJJ5/ElltuGfXq1Vsn98zqP3lKf1DNnDkzmjVrVtO3A7WSfye1U/rEPHXgbdq0qelbqfP9daLPrv38twhWz7+TuttfC93/rVGjRtG5c+eYOHFi9O7du9wpp/3+/fsv175x48Z5q6xFixbr7H756tJ/lPyHCVbNv5Paxwh39fTXiT677vDfIlg9/07qXn8tdFeSPgXv27dvdOnSJfbee+8YPnx4zJs3L1dHBQBqB/01AHWJ0F3JcccdFx9//HEMHjw4Zs2aFZ06dYrx48cvV6wFAKg5+msA6hKhexlpatrKpqdRt6SphJdeeulyUwqB/+HfCXWV/nr94r9FsHr+ndRd9SqsRwIAAACFqF/MZQEAAAChGwAAAAoidAMAAEBBhG7WWyNHjoztt98+mjRpEl27do3nn3++pm8JapUnnngijjzyyGjTpk3Uq1cv7r///pq+JWADpL+GVdNf131CN+ulMWPG5HVcU4XHl156KTp27Bi9evWK2bNn1/StQa2R1jVO/zbSH7wANUF/Daunv677VC9nvZQ+Kd9rr73ixhtvzPtLly6Ntm3bxrnnnhsXX3xxTd8e1Drpk/OxY8dG7969a/pWgA2I/hrWjP66bjLSzXpn4cKFMXXq1OjRo0f5WP369fP+lClTavTeAID/or8GNhRCN+udv/3tb7FkyZJo1apVleNpf9asWTV2XwDA/9BfAxsKoRsAAAAKInSz3tlqq62iQYMG8dFHH1U5nvZbt25dY/cFAPwP/TWwoRC6We80atQoOnfuHBMnTiwfS4VZ0n63bt1q9N4AgP+ivwY2FA1r+gagCGn5kb59+0aXLl1i7733juHDh+flFk499dSavjWoNT7//PN45513yvszZsyIadOmxRZbbBHbbbddjd4bsGHQX8Pq6a/rPkuGsd5Ky48MGzYsF2Pp1KlTXH/99XlpEuC/TJ48OQ466KDljqc/gO+4444auSdgw6O/hlXTX9d9QjcAAAAUxDPdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN1ArVGvXr24//7789fvvfde3p82bVpN3xYAUIn+GtZMwzVsD7BOtG3bNj788MPYaqutavpWAICV0F/D6hnpBtaphQsXfqV2DRo0iNatW0fDhj4bBIB1TX8N1UfoBlZr6dKlMXTo0Nhpp52icePGsd1228UvfvGLfO6iiy6Kb3/727HxxhvHN7/5zfjZz34WixYtKn/vZZddFp06dYpbb701dthhh2jSpEk+/vbbb0f37t3z/m677RYTJkyo8p4rmq72+OOPx957753vYZtttomLL744Fi9evM5+DwBQm+mvoXbykRSwWoMGDYpbbrklrrvuuth///3zNLK33norn9tss83ijjvuiDZt2sSrr74a/fr1y8cGDhxY/v533nkn/uM//iN+97vf5U/E0x8FRx99dLRq1Sqee+65+Oyzz+K8885b5T389a9/jcMPPzxOOeWUuOuuu/L7p/dKfwSkPxQAYEOnv4ZaqgJgFebOnVvRuHHjiltuueUrtR82bFhF586dy/uXXnppxUYbbVQxe/bs8rFHHnmkomHDhhV//etfy8f+8Ic/VKT/JI0dOzbvz5gxI++//PLLef+nP/1pxc4771yxdOnS8veMHDmyYtNNN61YsmRJtfysAFBX6a+h9jLSDazSm2++GQsWLIhDDjlkhefHjBkT119/fbz77rvx+eef5+ljzZo1q9KmXbt2sfXWW1e5Ziq8kj5tL+nWrdtq7yO1SVPYSvbbb7/8nn/5y1/yFDoA2FDpr6H28kw3sEpNmzZd6bkpU6ZEnz598jSycePGxcsvvxz/5//8n+WKr2yyySbr4E4BYMOlv4baS+gGVulb3/pW7sgnTpy43LlnnnkmfyqeOu4uXbrktv/v//2/1V5z1113jZkzZ+ZnzUqeffbZ1X5P+qOhoiLNYvsvTz/9dH4ebdttt13jnwsA1if6a6i9TC8HVikVPkkVT1OhlUaNGuUpYh9//HG8/vrrudN+//3345577om99torHnrooRg7duxqr9mjR49cQbVv374xbNiwmDt3bv5DYFV+9KMfxfDhw+Pcc8+N/v37x/Tp0+PSSy+NAQMGRP36Pj8EYMOmv4bay//zgdVKy4pccMEFMXjw4PwJ9nHHHRezZ8+Of/7nf47zzz8/d6ppmZH0SXpquzqp002d/ZdffpmXFDnjjDPKS5qszDe+8Y14+OGH4/nnn4+OHTvGWWedFaeffnpccskl1fiTAkDdpb+G2qleqqZW0zcBAAAA6yMj3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAACIYvx/ebH+C6NE+q0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the counts for training and test dataset\n",
    "fig, ax = plt.subplots(1,2,figsize = (10,5))\n",
    "sns.countplot(data=df, x = y_train, ax = ax[0])\n",
    "ax[0].set_title(\"Train Set\")\n",
    "sns.countplot(data=df, x = y_test, ax = ax[1])\n",
    "ax[1].set_title(\"Test Set\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us find the neural network architecture for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input Layer with fixed unit choices\n",
    "    model.add(Dense(hp.Choice('units', [128, 256, 512, 1024])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.05, 0.01, 0.001])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=['val_recall','val_precision'],  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='One hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 00m 32s]\n",
      "multi_objective: -1.4779848456382751\n",
      "\n",
      "Best multi_objective So Far: -1.4980929493904114\n",
      "Total elapsed time: 00h 02m 58s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    epochs=15,  \n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=64,\n",
    "    #callbacks=[early_stopping],  # Use Early Stopping\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best number of units in the first layer: 256\n",
      "Best activation function: leaky_relu\n",
      "Best dropout rate: 0.3\n",
      "Best optimizer: adam\n",
      "Best learning rate: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best number of units in the first layer: {best_hps.get('units')}\n",
    "Best activation function: {best_hps.get('activation')}\n",
    "Best dropout rate: {best_hps.get('dropout')}\n",
    "Best optimizer: {best_hps.get('optimizer')}\n",
    "Best learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.6286 - precision_3: 0.6946 - recall_3: 0.6507 - val_loss: 0.5955 - val_precision_3: 0.7383 - val_recall_3: 0.6712\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6267 - precision_3: 0.6962 - recall_3: 0.6410 - val_loss: 0.6141 - val_precision_3: 0.7042 - val_recall_3: 0.7464\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6223 - precision_3: 0.6973 - recall_3: 0.6465 - val_loss: 0.5792 - val_precision_3: 0.6975 - val_recall_3: 0.7535\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6315 - precision_3: 0.6928 - recall_3: 0.6464 - val_loss: 0.5705 - val_precision_3: 0.7583 - val_recall_3: 0.6491\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6306 - precision_3: 0.6939 - recall_3: 0.6398 - val_loss: 0.5879 - val_precision_3: 0.7491 - val_recall_3: 0.6363\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6374 - precision_3: 0.6895 - recall_3: 0.6479 - val_loss: 0.6006 - val_precision_3: 0.8000 - val_recall_3: 0.5459\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6326 - precision_3: 0.6890 - recall_3: 0.6349 - val_loss: 0.6211 - val_precision_3: 0.8285 - val_recall_3: 0.4458\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6425 - precision_3: 0.6856 - recall_3: 0.6328 - val_loss: 0.5794 - val_precision_3: 0.7505 - val_recall_3: 0.6456\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6277 - precision_3: 0.6933 - recall_3: 0.6427 - val_loss: 0.6510 - val_precision_3: 0.8293 - val_recall_3: 0.4065\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6366 - precision_3: 0.6886 - recall_3: 0.6416 - val_loss: 0.5937 - val_precision_3: 0.7494 - val_recall_3: 0.6672\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6373 - precision_3: 0.6855 - recall_3: 0.6303 - val_loss: 0.6028 - val_precision_3: 0.8168 - val_recall_3: 0.5004\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6240 - precision_3: 0.6930 - recall_3: 0.6468 - val_loss: 0.5946 - val_precision_3: 0.7984 - val_recall_3: 0.5662\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6375 - precision_3: 0.6892 - recall_3: 0.6336 - val_loss: 0.5935 - val_precision_3: 0.6672 - val_recall_3: 0.8177\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6474 - precision_3: 0.6974 - recall_3: 0.6522 - val_loss: 0.5860 - val_precision_3: 0.7921 - val_recall_3: 0.5717\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6328 - precision_3: 0.6963 - recall_3: 0.6499 - val_loss: 0.7135 - val_precision_3: 0.5891 - val_recall_3: 0.8711\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6304 - precision_3: 0.6898 - recall_3: 0.6417 - val_loss: 0.6028 - val_precision_3: 0.7794 - val_recall_3: 0.5757\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6414 - precision_3: 0.6878 - recall_3: 0.6399 - val_loss: 0.5760 - val_precision_3: 0.7086 - val_recall_3: 0.7370\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6251 - precision_3: 0.6938 - recall_3: 0.6405 - val_loss: 0.5832 - val_precision_3: 0.7277 - val_recall_3: 0.6961\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6314 - precision_3: 0.6913 - recall_3: 0.6495 - val_loss: 0.5702 - val_precision_3: 0.7410 - val_recall_3: 0.6787\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.6284 - precision_3: 0.6964 - recall_3: 0.6390 - val_loss: 0.6639 - val_precision_3: 0.5763 - val_recall_3: 0.9301\n",
      "Test Recall: 0.9301\n",
      "Test Precision: 0.5763\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall, precision = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>3378</td>\n",
       "      <td>7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>719</td>\n",
       "      <td>9568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         3378         7035\n",
       "Actual 1          719         9568"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.54%\n",
      "Precision: 57.63%\n",
      "Recall: 93.01%\n",
      "F1_score: 71.16%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with two hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for Keras Tuner with reduced search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256,512])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.005, 0.001, 0.0005])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=['val_recall','val_precision'],  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Two hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 01m 07s]\n",
      "multi_objective: -1.4503094553947449\n",
      "\n",
      "Best multi_objective So Far: -1.4756757020950317\n",
      "Total elapsed time: 00h 06m 40s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=15,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 128\n",
      "- Layer 1 Activation: leaky_relu\n",
      "- Layer 2 Dropout: 0.3\n",
      "- Layer 2 Units: 64\n",
      "- Layer 2 Activation: leaky_relu\n",
      "- Layer 2 Dropout: 0.1\n",
      "- Optimizer: rmsprop\n",
      "- Learning Rate: 0.005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5703 - precision_3: 0.7307 - recall_3: 0.6873 - val_loss: 0.5527 - val_precision_3: 0.7563 - val_recall_3: 0.6636\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5556 - precision_3: 0.7527 - recall_3: 0.6853 - val_loss: 0.5631 - val_precision_3: 0.7654 - val_recall_3: 0.6456\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5609 - precision_3: 0.7444 - recall_3: 0.6849 - val_loss: 0.5783 - val_precision_3: 0.7674 - val_recall_3: 0.6449\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5590 - precision_3: 0.7396 - recall_3: 0.6959 - val_loss: 0.5520 - val_precision_3: 0.7503 - val_recall_3: 0.6799\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5609 - precision_3: 0.7430 - recall_3: 0.6908 - val_loss: 0.5644 - val_precision_3: 0.7325 - val_recall_3: 0.7169\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5538 - precision_3: 0.7438 - recall_3: 0.6984 - val_loss: 0.5524 - val_precision_3: 0.7370 - val_recall_3: 0.7154\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5558 - precision_3: 0.7490 - recall_3: 0.6886 - val_loss: 0.5578 - val_precision_3: 0.7301 - val_recall_3: 0.7240\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5587 - precision_3: 0.7450 - recall_3: 0.6959 - val_loss: 0.5535 - val_precision_3: 0.7604 - val_recall_3: 0.6651\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5599 - precision_3: 0.7438 - recall_3: 0.6878 - val_loss: 0.5570 - val_precision_3: 0.7396 - val_recall_3: 0.7110\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5602 - precision_3: 0.7453 - recall_3: 0.6976 - val_loss: 0.5778 - val_precision_3: 0.7407 - val_recall_3: 0.7088\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5595 - precision_3: 0.7500 - recall_3: 0.6829 - val_loss: 0.5496 - val_precision_3: 0.7536 - val_recall_3: 0.6804\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5574 - precision_3: 0.7484 - recall_3: 0.6946 - val_loss: 0.5617 - val_precision_3: 0.7304 - val_recall_3: 0.7305\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5586 - precision_3: 0.7403 - recall_3: 0.6883 - val_loss: 0.5504 - val_precision_3: 0.7257 - val_recall_3: 0.7388\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5552 - precision_3: 0.7460 - recall_3: 0.6985 - val_loss: 0.5582 - val_precision_3: 0.7598 - val_recall_3: 0.6680\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5613 - precision_3: 0.7475 - recall_3: 0.6904 - val_loss: 0.5551 - val_precision_3: 0.7372 - val_recall_3: 0.7170\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5554 - precision_3: 0.7465 - recall_3: 0.6979 - val_loss: 0.5622 - val_precision_3: 0.7558 - val_recall_3: 0.6766\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5603 - precision_3: 0.7511 - recall_3: 0.6779 - val_loss: 0.5571 - val_precision_3: 0.7534 - val_recall_3: 0.6871\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5604 - precision_3: 0.7536 - recall_3: 0.6845 - val_loss: 0.5561 - val_precision_3: 0.7768 - val_recall_3: 0.6382\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5607 - precision_3: 0.7492 - recall_3: 0.6880 - val_loss: 0.5488 - val_precision_3: 0.7309 - val_recall_3: 0.7234\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5564 - precision_3: 0.7469 - recall_3: 0.6920 - val_loss: 0.5500 - val_precision_3: 0.7616 - val_recall_3: 0.6668\n",
      "Test Recall: 0.6668\n",
      "Test Precision: 0.7616\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall, precision = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>8266</td>\n",
       "      <td>2147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3428</td>\n",
       "      <td>6859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         8266         2147\n",
       "Actual 1         3428         6859"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.07%\n",
      "Precision: 76.16%\n",
      "Recall: 66.68%\n",
      "F1_score: 71.10%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with three hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for Keras Tuner with reduced search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256,512])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    model.add(Dense(hp.Choice('units_3', [32, 64, 128])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_3', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_3', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.005, 0.001, 0.0005])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=['val_recall','val_precision'],  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Three hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 01m 06s]\n",
      "multi_objective: -1.4476585984230042\n",
      "\n",
      "Best multi_objective So Far: -1.4825225472450256\n",
      "Total elapsed time: 00h 07m 27s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=15,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 256\n",
      "- Layer 1 Activation: relu\n",
      "- Layer 2 Dropout: 0.2\n",
      "- Layer 2 Units: 256\n",
      "- Layer 2 Activation: leaky_relu\n",
      "- Layer 2 Dropout: 0.2\n",
      "- Layer 3 Units: 64\n",
      "- Layer 3 Activation: relu\n",
      "- Layer 3 Dropout: 0.2\n",
      "- Optimizer: rmsprop\n",
      "- Learning Rate: 0.005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Layer 3 Units: {best_hps.get('units_3')}\n",
    "- Layer 3 Activation: {best_hps.get(f'activation_3')}\n",
    "- Layer 3 Dropout: {best_hps.get('dropout_3')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.5868 - precision_3: 0.7290 - recall_3: 0.6812 - val_loss: 0.5771 - val_precision_3: 0.7339 - val_recall_3: 0.7121\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.5683 - precision_3: 0.7445 - recall_3: 0.6821 - val_loss: 0.5614 - val_precision_3: 0.7461 - val_recall_3: 0.6874\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5678 - precision_3: 0.7394 - recall_3: 0.6864 - val_loss: 0.5549 - val_precision_3: 0.7471 - val_recall_3: 0.6815\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5635 - precision_3: 0.7440 - recall_3: 0.6928 - val_loss: 0.5616 - val_precision_3: 0.7475 - val_recall_3: 0.6925\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5676 - precision_3: 0.7436 - recall_3: 0.6791 - val_loss: 0.5538 - val_precision_3: 0.7143 - val_recall_3: 0.7561\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5604 - precision_3: 0.7401 - recall_3: 0.7053 - val_loss: 0.5634 - val_precision_3: 0.7116 - val_recall_3: 0.7572\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5610 - precision_3: 0.7404 - recall_3: 0.6932 - val_loss: 0.5578 - val_precision_3: 0.7464 - val_recall_3: 0.6870\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5675 - precision_3: 0.7402 - recall_3: 0.6992 - val_loss: 0.5583 - val_precision_3: 0.7244 - val_recall_3: 0.7340\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5635 - precision_3: 0.7451 - recall_3: 0.6988 - val_loss: 0.5616 - val_precision_3: 0.7433 - val_recall_3: 0.7002\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5676 - precision_3: 0.7446 - recall_3: 0.6853 - val_loss: 0.5600 - val_precision_3: 0.7346 - val_recall_3: 0.7142\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5663 - precision_3: 0.7353 - recall_3: 0.6989 - val_loss: 0.5543 - val_precision_3: 0.7372 - val_recall_3: 0.7062\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5682 - precision_3: 0.7426 - recall_3: 0.6880 - val_loss: 0.5546 - val_precision_3: 0.7350 - val_recall_3: 0.7122\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5674 - precision_3: 0.7365 - recall_3: 0.7066 - val_loss: 0.5553 - val_precision_3: 0.7573 - val_recall_3: 0.6703\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5703 - precision_3: 0.7347 - recall_3: 0.7028 - val_loss: 0.5510 - val_precision_3: 0.7350 - val_recall_3: 0.7170\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5720 - precision_3: 0.7349 - recall_3: 0.7061 - val_loss: 0.5536 - val_precision_3: 0.7236 - val_recall_3: 0.7360\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5697 - precision_3: 0.7398 - recall_3: 0.7001 - val_loss: 0.5786 - val_precision_3: 0.7613 - val_recall_3: 0.6692\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5697 - precision_3: 0.7429 - recall_3: 0.6977 - val_loss: 0.5888 - val_precision_3: 0.7247 - val_recall_3: 0.7317\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5809 - precision_3: 0.7393 - recall_3: 0.6958 - val_loss: 0.5590 - val_precision_3: 0.7648 - val_recall_3: 0.6556\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5711 - precision_3: 0.7330 - recall_3: 0.7088 - val_loss: 0.5698 - val_precision_3: 0.7519 - val_recall_3: 0.6816\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5784 - precision_3: 0.7304 - recall_3: 0.7080 - val_loss: 0.5848 - val_precision_3: 0.7214 - val_recall_3: 0.7414\n",
      "Test Recall: 0.7414\n",
      "Test Precision: 0.7214\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall,precision = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>7467</td>\n",
       "      <td>2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2660</td>\n",
       "      <td>7627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         7467         2946\n",
       "Actual 1         2660         7627"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.92%\n",
      "Precision: 72.14%\n",
      "Recall: 74.14%\n",
      "F1_score: 73.13%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
